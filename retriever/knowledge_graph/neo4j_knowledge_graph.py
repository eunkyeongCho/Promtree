from neo4j import GraphDatabase
from neo4j.exceptions import Neo4jError
from pymongo import MongoClient

from pathlib import Path
import requests
from dotenv import load_dotenv
import os
import json
from typing import Any
import asyncio


class Neo4jKnowledgeGraph:

    BASE_DIR = Path(__file__).resolve().parents[2]  # root ê²½ë¡œ
    load_dotenv(BASE_DIR / "common" / ".env")
    
    NEO4J_URI = os.getenv("NEO4J_URI")
    NEO4J_AUTH = ("neo4j", os.getenv("NEO4J_PASSWORD"))

    RUNPOD_URI = os.getenv("RUNPOD_URI")
    RUNPOD_LLM_MODEL = os.getenv("RUNPOD_LLM_MODEL")

    TIMEOUT = os.getenv("TIMEOUT")
    MAX_CONCURRENT = int(os.getenv("MAX_ASYNC_REQUESTS"))

    def __init__(self):
        

        self.neo4j_driver = GraphDatabase.driver(self.NEO4J_URI, auth=self.NEO4J_AUTH)

        USERNAME = os.getenv("MONGO_INITDB_ROOT_USERNAME", "root")
        PASSWORD = os.getenv("MONGO_INITDB_ROOT_PASSWORD", "example")
        HOST = os.getenv("MONGO_HOST", "localhost")
        PORT = int(os.getenv("MONGO_PORT", 27017))

        self.mongodb_client = MongoClient(f"mongodb://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/")
        self.chunk_collection = self.mongodb_client["chunk_db"]["chunk_collection"]

        try:
            self.neo4j_driver.verify_connectivity()
            print("Connection established.")
        except Neo4jError as e:
            print(f"Connection failed: {e.__cause__}")  # Neo4jErrorê°€ ì œê³µí•˜ëŠ” __cause__ ì†ì„±ì´ ì—ëŸ¬ ë©”ì„¸ì§€ê°€ ìì„¸í•˜ë¯€ë¡œ ì´ë¥¼ ì¶œë ¥

        self.PROMPT_FOR_NODES_AND_RELATIONSHIPS = """ë‹¹ì‹ ì€ RAGì˜ Knowledge Graphë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´, ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ ì£¼ìš”ê°œë…ê³¼ ê·¸ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ JSON í˜•ì‹ì„ ë”°ë¼ ë‘ê°œì˜ ì£¼ìš”ê°œë…ê³¼ ê·¸ ë‘˜ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        [ë‹µë³€í˜•ì‹]
        [{{
            "source_node": {{
                "name": "source_nodeì˜ ì´ë¦„",
                "alias": ["source_nodeì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹1", "source_nodeì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹2", ...]
            }},
            "target_node": {{
                "name": "target_nodeì˜ ì´ë¦„",
                "alias": ["target_nodeì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹1", "target_nodeì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹2", ...]
            }},
            "relationship_description": "relationshipì˜ ì´ë¦„",
            "confidence": ì¶”ì¶œ ê²°ê³¼ì˜ ì‹ ë¢°ë„ (0ê³¼ 1 ì‚¬ì´ì˜ ê°’)
        }}]

        ìœ„ì— ì œì‹œëœ ë‹µë³€ JSON í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ì£¼ì˜ì‚¬í•­ì„ ë”°ë¼ ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ ì£¼ìš”ê°œë…ê³¼ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        1. ì§ˆë¬¸ì—ì„œ ì¤‘ìš”í•œ ì£¼ìš”ê°œë…(ëª…ì‚¬, ê°œë…, ë¬¼ì§ˆëª…, í™”í•™ë¬¼ì§ˆ, ì¡°ì§, ì¸ë¬¼ ë“±)ë¥¼ ëª¨ë‘ ì¶”ì¶œí•˜ì„¸ìš”.
        2. ë¬¸ì„œ ë‚´ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš”ê°œë…ì˜ ë‹¤ë¥¸ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹ì´ ë“±ì¥í•œë‹¤ë©´ í•¨ê»˜ ì¶”ì¶œí•˜ê³ , source_nodeë¼ë©´ source_nodeì˜ alias, target_nodeë¼ë©´ target_nodeì˜ alias í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ê°’ì´ ì—¬ëŸ¬ê°œë¼ë©´ ë¬¸ìì—´ ë°°ì—´ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”. ë‹¨, ë¬¸ì„œ ë‚´ì— ë‹¤ë¥¸ í‘œí˜„ ë°©ì‹ì´ ë“±ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì¶”ì¶œí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ë‹¤ë¥¸ í‘œí˜„ ë°©ì‹ì´ 1ê°œì—¬ë„ ë°°ì—´ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”. (ì˜ˆ: ì—¼ì‚° â†’ ["HYDROCHLORIC ACID"])
        3. ì¶”ì¶œí•œ ì£¼ìš”ê°œë… ì¤‘ ì„œë¡œ ì—°ê´€ê´€ê³„ë¥¼ ê°€ì§€ëŠ” ê²ƒì´ ìˆë‹¤ë©´ ê´€ê³„ì˜ ì‹œì‘ì— í•´ë‹¹í•˜ëŠ” ì£¼ìš”ê°œë…ì„ source_node, ê´€ê³„ì˜ ì ìš©ëŒ€ìƒì— í•´ë‹¹í•˜ëŠ” ì£¼ìš”ê°œë…ì„ target_nodeë¡œ ì œì‹œí•˜ì„¸ìš”. ì œì‹œí•  ìˆ˜ ìˆëŠ” ê´€ê³„ì˜ ì¢…ë¥˜ì—ëŠ” ì œí•œì´ ì—†ìŠµë‹ˆë‹¤. ë‹¨, ë  ìˆ˜ ìˆëŠ” í•œ ê°„ë‹¨í•œ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. (ex. "êµ¬ì„±ë¬¼ì§ˆì„ ê°€ì§„ë‹¤", "í‰ê°€ ê²°ê³¼ë¥¼ ê°€ì§„ë‹¤", "ì‹œí—˜ ë°©ë²•ìœ¼ë¡œ í‰ê°€ë˜ì—ˆë‹¤")
        4. ê´€ê³„ì˜ ì´ë¦„ì€ relationship í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.
        5. ì¶”ì¶œí•œ ì£¼ìš”ê°œë…ë“¤ê³¼ ê·¸ ê´€ê³„ì— ëŒ€í•œ ì‹ ë¢°ë„ë¥¼ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ê³„ì‚°í•˜ê³ , confidence í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ì†Œìˆ˜ì ì€ ìµœëŒ€ 10ìë¦¬ê¹Œì§€ë§Œ ì œì‹œí•˜ì„¸ìš”. ë¬¼ë¡ , ì†Œìˆ˜ì  ë°‘ ìë¦¬ê°€ 10ìë¦¬ ë³´ë‹¤ ì ë‹¤ë©´ 10ìë¦¬ë¥¼ ì±„ìš°ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì œì‹œí•˜ì„¸ìš”.
        6. ë‹µë³€ì—ëŠ” ë‹µë³€í˜•ì‹ì¸ JSON ë°°ì—´ì„ ì œì™¸í•œ ê·¸ ì–´ë–¤ ë¬¸êµ¬ë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ì •í™•íˆ ë‹µë³€ JSON ë°°ì—´ë§Œì„ ë‹µë³€í•˜ì„¸ìš”. (ë‹¨, ì£¼ìš”ê°œë…ë“¤ê³¼ ê´€ê³„ì˜ ìŒì´ í•˜ë‚˜ì—¬ë„ ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.)

        [ì£¼ìš”ê°œë… ë° ê´€ê³„ë¥¼ ì¶”ì¶œí•´ì•¼ í•  ë¬¸ìì—´]
        {text_to_analyze}

        [ë‹µë³€ ì˜ˆì‹œ]
        [{{
        "source_node": {{
            "name": "Triethylene Glycol",
            "alias": ["2,2 ethylenedioxydiethanol", "Ethylene triglycol", "glycol bis (hydroxyethyl) ether", "TEG", "Triglycol"]
        }},
        "target_node": {{
            "name": "SHELL EASTERN CHEMICALS (S) A",
            "alias": ["SHELL EASTERN TRADING (PTE) LTD", "Shell Eastern Chemicals"]
        }},
        "relationship_description": "ì œì¡° ë˜ëŠ” ê³µê¸‰í•œë‹¤",
        "confidence": 0.97
        }}]
        """

        self.PROMPT_FOR_NODES = """ë‹¹ì‹ ì€ RAGì˜ Knowledge Graphë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´, ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ ì£¼ìš”ê°œë…ì„ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ JSON í˜•ì‹ì„ ë”°ë¼ ì£¼ìš”ê°œë…ì„ ì¶”ì¶œí•˜ì„¸ìš”.

        [ë‹µë³€í˜•ì‹]
        [{{
            "name": "ì£¼ìš”ê°œë…ì˜ ì´ë¦„",
            "alias": ["ì£¼ìš”ê°œë…ì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹1", "ì£¼ìš”ê°œë…ì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹2", ...]
            "confidence": ì¶”ì¶œ ê²°ê³¼ì˜ ì‹ ë¢°ë„ (0ê³¼ 1 ì‚¬ì´ì˜ ê°’)
        }}]

        ìœ„ì— ì œì‹œëœ ë‹µë³€ JSON í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ì£¼ì˜ì‚¬í•­ì„ ë”°ë¼ ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ ì£¼ìš”ê°œë…ì„ ì¶”ì¶œí•˜ì„¸ìš”.

        1. ì§ˆë¬¸ì—ì„œ ì¤‘ìš”í•œ ì£¼ìš”ê°œë…(ëª…ì‚¬, ê°œë…, ë¬¼ì§ˆëª…, í™”í•™ë¬¼ì§ˆ, ì¡°ì§, ì¸ë¬¼ ë“±)ë¥¼ ëª¨ë‘ ì¶”ì¶œí•˜ì„¸ìš”.
        2. ë¬¸ì„œ ë‚´ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš”ê°œë…ì˜ ë‹¤ë¥¸ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹ì´ ë“±ì¥í•œë‹¤ë©´ í•¨ê»˜ ì¶”ì¶œí•˜ê³ , alias í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ê°’ì´ ì—¬ëŸ¬ê°œë¼ë©´ ë¬¸ìì—´ ë°°ì—´ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”. ë‹¨, ë¬¸ì„œ ë‚´ì— ë‹¤ë¥¸ í‘œí˜„ ë°©ì‹ì´ ë“±ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì¶”ì¶œí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ë‹¤ë¥¸ í‘œí˜„ ë°©ì‹ì´ 1ê°œì—¬ë„ ë°°ì—´ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”. (ì˜ˆ: ì—¼ì‚° â†’ ["HYDROCHLORIC ACID"])
        3. ì¶”ì¶œí•œ ì£¼ìš”ê°œë…ì— ëŒ€í•œ ì‹ ë¢°ë„ë¥¼ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ê³„ì‚°í•˜ê³ , confidence í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ì†Œìˆ˜ì ì€ ìµœëŒ€ 10ìë¦¬ê¹Œì§€ë§Œ ì œì‹œí•˜ì„¸ìš”. ë¬¼ë¡ , ì†Œìˆ˜ì  ë°‘ ìë¦¬ê°€ 10ìë¦¬ ë³´ë‹¤ ì ë‹¤ë©´ 10ìë¦¬ë¥¼ ì±„ìš°ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì œì‹œí•˜ì„¸ìš”.
        4. ë‹µë³€ì—ëŠ” ë‹µë³€í˜•ì‹ì¸ JSON ë°°ì—´ì„ ì œì™¸í•œ ê·¸ ì–´ë–¤ ë¬¸êµ¬ë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ì •í™•íˆ ë‹µë³€ JSON ë°°ì—´ë§Œì„ ë‹µë³€í•˜ì„¸ìš”. (ë‹¨, ì£¼ìš”ê°œë…ì´ í•˜ë‚˜ì—¬ë„ ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.)

        [ì£¼ìš”ê°œë…ì„ ì¶”ì¶œí•´ì•¼ í•  ë¬¸ìì—´]
        {text_to_analyze}

        [ë‹µë³€ ì˜ˆì‹œ]
        [{{
            "name": "SHELL EASTERN CHEMICALS (S)",
            "alias": ["SHELL EASTERN TRADING (PTE) LTD", "Shell Eastern Chemicals", "SHELL EASTERN CHEMICALS"],
            "confidence": 0.98
        }}]
        """


    def close(self):
        """
        Neo4j ë“œë¼ì´ë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
        - ë“œë¼ì´ë²„ ì¢…ë£Œí•´ë„ ë°ì´í„°ëŠ” ë³´ì¡´ë©ë‹ˆë‹¤.
        - ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ ìœ„í•´, í•œ íŒŒì´í”„ ë¼ì¸ì—ì„œ ì‚¬ìš©ì´ ì¢…ë£Œë˜ë©´ ë°˜ë“œì‹œ close() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•´ì£¼ì„¸ìš”.
        """
        self.neo4j_driver.close()
        print("â˜‘ï¸ Neo4j driver successfully closed.")


    async def _async_extract_nodes_or_relationships(self, semaphore: asyncio.Semaphore, text_to_analyze: str, need_relationships: bool) -> list[dict[str, Any]]:
        """
        ì£¼ì–´ì§„ ë¬¸ìì—´ ë°°ì—´ì—ì„œ ë…¸ë“œ ë˜ëŠ” ê´€ê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            content(list[str]): ë…¸ë“œ ë˜ëŠ” ê´€ê³„ë¥¼ ì¶”ì¶œí•´ì•¼í•  ë¬¸ìì—´ ë°°ì—´
            need_relationships(bool):
                - True: ë…¸ë“œì™€ ê´€ê³„ ëª¨ë‘ ì¶”ì¶œ (ì²­í¬ë¥¼ neo4jì— ì €ì¥í•  ë•Œ ì‚¬ìš©)
                - False: ë…¸ë“œë§Œ ì¶”ì¶œ (ì¿¼ë¦¬ë¥¼ ë°›ì•„ì„œ ê·¸ë˜í”„ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©)

        Returns:
            list[dict[str, Any]]: ë…¸ë“œì™€ ê´€ê³„ ëª©ë¡
        """

        if need_relationships:
            prompt = self.PROMPT_FOR_NODES_AND_RELATIONSHIPS.format(text_to_analyze=text_to_analyze)
        else:
            prompt = self.PROMPT_FOR_NODES.format(text_to_analyze=text_to_analyze)

        async with semaphore:
            def sync_request():
                url = f"{self.RUNPOD_URI}/api/generate"
                payload = {"model": self.RUNPOD_LLM_MODEL, "prompt": prompt, "stream": False}
                headers = {"Content-Type": "application/json"}
                timeout = float(self.TIMEOUT) if self.TIMEOUT else None
                return requests.post(url, json=payload, headers=headers, timeout=timeout)

            try:
                response = await asyncio.to_thread(sync_request)
                content_type = response.headers.get("Content-Type", "")

                if "application/json" in content_type:
                    raw_data = response.json()
                    data = raw_data['response']
                    print(f"ğŸ” LLM response: {json.loads(data)}")
                    return json.loads(data)
                else:
                    raw_data = response.text
                    print(f"âš ï¸ LLM Message: {raw_data}")
                    return raw_data

            except Exception as e:
                print(f"âŒ LLM async request failed: {e}")
                return []

    
    # file_nameì„ ë°›ì•„ì„œ, MongoDBì—ì„œ í•´ë‹¹ ì²­í¬ë“¤ì„ ì°¾ì•„ì„œ, ë°˜ë³µë¬¸ì„ ëŒë©´ì„œ ê°ê° ë…¸ë“œì™€ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ê³ , neo4jì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜(ì €ì¥í•  ë•Œ merge ì‚¬ìš©)
    async def async_ingest_chunks(self, chunks: list[dict]) -> bool:
        """
        ì²­í¬ë“¤ì„ ì§ì ‘ ë§¤ê°œê°’ìœ¼ë¡œ ë°›ê³  chunk ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë…¸ë“œ/ê´€ê³„ë¥¼ ìƒì„±í•˜ì—¬ Neo4jì— MERGE í•©ë‹ˆë‹¤.

        Args:
            chunks(list[str]): ì²­í¬ ë°°ì—´

        Returns:
            bool: í•˜ë‚˜ ì´ìƒì˜ chunkê°€ ì •ìƒ ì €ì¥ë˜ë©´ True, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ False
        """

        if not chunks:
            print("âš ï¸ No chunks provided.")
            return False

        extract_success_count = 0  # ì¶”ì¶œì— ì„±ê³µí•œ
        extract_fail_count = 0  # ì¶”ì¶œì— ì‹¤íŒ¨í•œ
        save_success_count = 0  # ì €ì¥ì— ì„±ê³µí•œ
        save_fail_count = 0  # ì €ì¥ì— ì‹¤íŒ¨í•œ

        semaphore = asyncio.Semaphore(self.MAX_CONCURRENT)

        tasks = []
        for chunk in chunks:
            if chunk.get("type") in {"text", "table"}:
                text_to_analyze = chunk.get("content", "")
            else:
                text_to_analyze = chunk.get("metadata", "")

            if not text_to_analyze:
                print("âš ï¸ Skipping chunk with empty content.")
                continue

            tasks.append(self._async_extract_nodes_or_relationships(semaphore, text_to_analyze, True))

        print(f"ğŸš€ Sending {len(tasks)} LLM requests concurrently... (max concurrent: {self.MAX_CONCURRENT})")
        print(f"ğŸ” LLM responses received. Inserting into Neo4j...")

        all_chunks_nodes_and_relationships = await asyncio.gather(*tasks, return_exceptions=True)

        for i, result in enumerate(all_chunks_nodes_and_relationships):
            if isinstance(result, Exception):
                print(f"âŒ Task {i} failed with error: {result}")
                extract_fail_count += 1
            else:
                print(f"âœ… Task {i} succeeded, got {len(result)} relationships")
                extract_success_count += 1

        for chunk_nodes_and_relationships in all_chunks_nodes_and_relationships:  # ë°”ê¹¥ list forë¬¸ ëŒë©´ list í•˜ë‚˜ì”© ë‚˜ì˜´!
            if not isinstance(chunk_nodes_and_relationships, list):
                continue

            for nodes_and_relationship in chunk_nodes_and_relationships:  # ê·¸ listëŠ” dictì˜ ë°°ì—´ì´ê¸° ë•Œë¬¸ì—, ë˜ ë°˜ë³µë¬¸ ëŒë©´ dictê°€ í•˜ë‚˜ì”© ë‚˜ì˜´!
                relation_description = nodes_and_relationship.get("relationship_description")

                if not relation_description:
                    print("âš ï¸ Skipping relationship without description.")
                    continue

                try:
                    self.neo4j_driver.execute_query(
                        """
                        MERGE (source:Entity {name: $source_name, alias: $source_alias, file_info: $source_file_info})
                        MERGE (target:Entity {name: $target_name, alias: $target_alias, file_info: $target_file_info})
                        MERGE (source)-[relationship:`%s` {confidence: $confidence}]->(target)
                        """
                        % relation_description,
                        source_name=nodes_and_relationship["source_node"]["name"],
                        source_alias=nodes_and_relationship["source_node"]["alias"],
                        source_file_info=json.dumps(chunk.get("file_info", {})),
                        target_name=nodes_and_relationship["target_node"]["name"],
                        target_alias=nodes_and_relationship["target_node"]["alias"],
                        target_file_info=json.dumps(chunk.get("file_info", {})),
                        confidence=float(nodes_and_relationship["confidence"]),
                        database_="neo4j"  # ë¬´ë£Œ ë²„ì „ì€ ì´ë¦„ì´ neo4jì¸ ë°ì´í„°ë² ì´ìŠ¤ í•˜ë‚˜ë§Œ ì‚¬ìš© ê°€ëŠ¥
                    )
                    save_success_count += 1
                except Neo4jError as e:
                    print(f"âŒ Failed to insert into Neo4j : {e.__cause__}")
                    save_fail_count += 1
                    continue

        if save_success_count > 0:
            print(f"âœ… Successfully extracted {extract_success_count}/{extract_success_count + extract_fail_count} from chunks.")
            print(f"âœ… Successfully inserted {save_success_count}/{save_success_count + save_fail_count} relationships into Neo4j.")
            return True
        else:
            print("âŒ No relationships were inserted into Neo4j.")
            return False

    
    def search_graph(self, query: str) -> list[dict[str, Any]]:

        semaphore = asyncio.Semaphore(self.MAX_CONCURRENT)
        nodes = self._async_extract_nodes_or_relationships(semaphore, query, False)
        confidence_results = []

        for node in nodes:
            try:
                records, summary, keys = self.neo4j_driver.execute_query(
                    """
                    MATCH (source:Entity)-[r]-(target:Entity)
                    WHERE source.name = $node_name
                        OR ANY(alias_item IN source.alias WHERE alias_item = $node_name)
                        OR target.name = $node_name
                        OR ANY(alias_item IN target.alias WHERE alias_item = $node_name)
                    RETURN source.name AS source,
                        source.file_info AS source_file_info,
                        type(r) AS relationship_description,
                        target.name AS target,
                        target.file_info AS target_file_info,
                        r.confidence AS confidence
                    """,
                    node_name=node['name'],
                    database_="neo4j"
                )
            except Neo4jError as e:
                print(f"âŒ Failed to search graph(Neo4jError): {e.__cause__}")
                continue

            except Exception as e:
                print(f"âŒ Failed to search graph: {e}")
                continue

            for record in records:
                confidence_results.append({
                    "graph": record["source"] + " - " + record["relationship_description"] + " -> " + record["target"],
                    "source_file_info": json.loads(record["source_file_info"]),
                    "target_file_info": json.loads(record["target_file_info"]),
                    "confidence": float(record["confidence"])
                })

        confidence_results.sort(key=lambda x: x["confidence"], reverse=True) # confidence ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬

        results = [] # confidence í‚¤ ì—†ì•¤ results
        for confidence_result in confidence_results:
            results.append({
                "graph": confidence_result["graph"],
                "source_file_info": confidence_result["source_file_info"],
                "target_file_info": confidence_result["target_file_info"]
            })

        print(f"ğŸ” Results: {results}")
        return results


    def generate_answer(self, query: str) -> str:
        """
        ë‹µë³€ìƒì„±
        """

        results = self.search_graph(query)

        prompt = f"""
        ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì™€ ê·¸ë˜í”„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëª¨ë‘ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê³  í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
        
        ì§ˆë¬¸: {query}
        ê·¸ë˜í”„ ê²€ìƒ‰ ê²°ê³¼: {results}
        """

        # ë‹µë³€ ìš”ì²­
        url = f"{self.RUNPOD_URI}/api/generate"
        payload = {"model": self.RUNPOD_LLM_MODEL, "prompt": prompt, "stream": False}
        timeout = float(self.TIMEOUT) if self.TIMEOUT else None
        response = requests.post(url, json=payload, timeout=timeout)

        try:
            response.raise_for_status() # ì—ëŸ¬ë©´ ì˜ˆì™¸ë°œìƒ
        except requests.RequestException as e:
            print(f"HTTP request failed: {e}")

        print(f"ğŸ” LLM response: {response.json()['response']}")
        return response.json()['response']

        
def main():
    """
    Neo4jKnowledgeGraph í†µí•´ ê·¸ë˜í”„ ì €ì¥ ë° ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.
    ë¨¼ì € í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì€ md ë¬¸ì„œì˜ ì²­í‚¹ì„ ì™„ë£Œí•œ í›„ì— ì‹¤í–‰í•´ì£¼ì„¸ìš”.
    """
    knowledge_graph = Neo4jKnowledgeGraph()

    asyncio.run(knowledge_graph.async_ingest_file("Copy of 5bc0c676-018f-46de-bb0d-0103ff9c388c")) # ì²­í‚¹í•œ ë¬¸ì„œ ì´ë¦„ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”
    # knowledge_graph.search_graph("ISA KitëŠ” ë¬´ì—‡ì„ í…ŒìŠ¤íŠ¸í•˜ë‚˜ìš”?") # ê²€ìƒ‰ ëŒ€ìƒì¸ ë¬¸ì„œì— ëŒ€í•œ ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”
    knowledge_graph.generate_answer("ISA KitëŠ” ë¬´ì—‡ì„ í…ŒìŠ¤íŠ¸í•˜ë‚˜ìš”?")
    knowledge_graph.close()

if __name__ == "__main__":
    main()