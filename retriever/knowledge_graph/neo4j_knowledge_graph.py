from neo4j import GraphDatabase
from neo4j.exceptions import Neo4jError
from pymongo import MongoClient

from pathlib import Path
import requests
from dotenv import load_dotenv
import os
import json
from typing import Any
import asyncio


class Neo4jKnowledgeGraph:

    BASE_DIR = Path(__file__).resolve().parents[2]  # root ê²½ë¡œ
    load_dotenv(BASE_DIR / "common" / ".env")
    
    NEO4J_URI = os.getenv("NEO4J_URI")
    NEO4J_AUTH = ("neo4j", os.getenv("NEO4J_PASSWORD"))

    RUNPOD_URI = os.getenv("RUNPOD_URI")
    RUNPOD_LLM_MODEL = os.getenv("RUNPOD_LLM_MODEL")

    TIMEOUT = os.getenv("TIMEOUT")
    MAX_CONCURRENT = int(os.getenv("MAX_ASYNC_REQUESTS"))

    def __init__(self):
        

        self.neo4j_driver = GraphDatabase.driver(self.NEO4J_URI, auth=self.NEO4J_AUTH)

        USERNAME = os.getenv("MONGO_INITDB_ROOT_USERNAME", "root")
        PASSWORD = os.getenv("MONGO_INITDB_ROOT_PASSWORD", "example")
        HOST = os.getenv("MONGO_HOST", "localhost")
        PORT = int(os.getenv("MONGO_PORT", 27017))

        self.mongodb_client = MongoClient(f"mongodb://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/")
        self.chunk_collection = self.mongodb_client["chunk_db"]["chunk_collection"]

        try:
            self.neo4j_driver.verify_connectivity()
            print("Connection established.")
        except Neo4jError as e:
            print(f"Connection failed: {e.__cause__}")  # Neo4jErrorê°€ ì œê³µí•˜ëŠ” __cause__ ì†ì„±ì´ ì—ëŸ¬ ë©”ì„¸ì§€ê°€ ìì„¸í•˜ë¯€ë¡œ ì´ë¥¼ ì¶œë ¥

        self.PROMPT_FOR_NODES_AND_RELATIONSHIPS = """ë‹¹ì‹ ì€ RAGì˜ Knowledge Graphë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´, ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ ì£¼ìš”ê°œë…ê³¼ ê·¸ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ JSON í˜•ì‹ì„ ë”°ë¼ ë‘ê°œì˜ ì£¼ìš”ê°œë…ê³¼ ê·¸ ë‘˜ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ìµœëŒ€í•œ ë§ì´ ì¶”ì¶œí•˜ì„¸ìš”.

        [ë‹µë³€í˜•ì‹]
        [{{
            "source_node": {{
                "name": "source_nodeì˜ ì´ë¦„",
                "alias": ["source_nodeì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹1", "source_nodeì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹2", ...]
            }},
            "target_node": {{
                "name": "target_nodeì˜ ì´ë¦„",
                "alias": ["target_nodeì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹1", "target_nodeì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹2", ...]
            }},
            "relationship_description": "relationshipì˜ ì´ë¦„",
            "confidence": ì¶”ì¶œ ê²°ê³¼ì˜ ì‹ ë¢°ë„ (0ê³¼ 1 ì‚¬ì´ì˜ ê°’)
        }}]

        ìœ„ì— ì œì‹œëœ ë‹µë³€ JSON í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ì£¼ì˜ì‚¬í•­ì„ ë”°ë¼ ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ ì£¼ìš”ê°œë…ê³¼ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

        1. ì§ˆë¬¸ì—ì„œ ì¤‘ìš”í•œ ì£¼ìš”ê°œë…(ëª…ì‚¬, ê°œë…, ë¬¼ì§ˆëª…, í™”í•™ë¬¼ì§ˆ, ì¡°ì§, ì¸ë¬¼ ë“±)ë¥¼ ëª¨ë‘ ì¶”ì¶œí•˜ì„¸ìš”.
        2. ë¬¸ì„œ ë‚´ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš”ê°œë…ì˜ ë‹¤ë¥¸ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹ì´ ë“±ì¥í•œë‹¤ë©´ í•¨ê»˜ ì¶”ì¶œí•˜ê³ , source_nodeë¼ë©´ source_nodeì˜ alias, target_nodeë¼ë©´ target_nodeì˜ alias í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ê°’ì´ ì—¬ëŸ¬ê°œë¼ë©´ ë¬¸ìì—´ ë°°ì—´ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”. ë‹¨, ë¬¸ì„œ ë‚´ì— ë‹¤ë¥¸ í‘œí˜„ ë°©ì‹ì´ ë“±ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì¶”ì¶œí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ë‹¤ë¥¸ í‘œí˜„ ë°©ì‹ì´ 1ê°œì—¬ë„ ë°°ì—´ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”. (ì˜ˆ: ì—¼ì‚° â†’ ["HYDROCHLORIC ACID"])
        3. ì¶”ì¶œí•œ ì£¼ìš”ê°œë… ì¤‘ ì„œë¡œ ì—°ê´€ê´€ê³„ë¥¼ ê°€ì§€ëŠ” ê²ƒì´ ìˆë‹¤ë©´ ê´€ê³„ì˜ ì‹œì‘ì— í•´ë‹¹í•˜ëŠ” ì£¼ìš”ê°œë…ì„ source_node, ê´€ê³„ì˜ ì ìš©ëŒ€ìƒì— í•´ë‹¹í•˜ëŠ” ì£¼ìš”ê°œë…ì„ target_nodeë¡œ ì œì‹œí•˜ì„¸ìš”. ì œì‹œí•  ìˆ˜ ìˆëŠ” ê´€ê³„ì˜ ì¢…ë¥˜ì—ëŠ” ì œí•œì´ ì—†ìŠµë‹ˆë‹¤. ë‹¨, ë  ìˆ˜ ìˆëŠ” í•œ ê°„ë‹¨í•œ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. (ex. "êµ¬ì„±ë¬¼ì§ˆì„ ê°€ì§„ë‹¤", "í‰ê°€ ê²°ê³¼ë¥¼ ê°€ì§„ë‹¤", "ì‹œí—˜ ë°©ë²•ìœ¼ë¡œ í‰ê°€ë˜ì—ˆë‹¤")
        4. ê´€ê³„ì˜ ì´ë¦„ì€ relationship í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.
        5. ì¶”ì¶œí•œ ì£¼ìš”ê°œë…ë“¤ê³¼ ê·¸ ê´€ê³„ì— ëŒ€í•œ ì‹ ë¢°ë„ë¥¼ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ê³„ì‚°í•˜ê³ , confidence í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ì†Œìˆ˜ì ì€ ìµœëŒ€ 10ìë¦¬ê¹Œì§€ë§Œ ì œì‹œí•˜ì„¸ìš”. ë¬¼ë¡ , ì†Œìˆ˜ì  ë°‘ ìë¦¬ê°€ 10ìë¦¬ ë³´ë‹¤ ì ë‹¤ë©´ 10ìë¦¬ë¥¼ ì±„ìš°ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì œì‹œí•˜ì„¸ìš”.
        6. ë‹µë³€ì—ëŠ” ë‹µë³€í˜•ì‹ì¸ JSON ë°°ì—´ì„ ì œì™¸í•œ ê·¸ ì–´ë–¤ ë¬¸êµ¬ë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ì •í™•íˆ ë‹µë³€ JSON ë°°ì—´ë§Œì„ ë‹µë³€í•˜ì„¸ìš”. (ë‹¨, ì£¼ìš”ê°œë…ë“¤ê³¼ ê´€ê³„ì˜ ìŒì´ í•˜ë‚˜ì—¬ë„ ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.)

        [ì£¼ìš”ê°œë… ë° ê´€ê³„ë¥¼ ì¶”ì¶œí•´ì•¼ í•  ë¬¸ìì—´]
        {text_to_analyze}

        [ë‹µë³€ ì˜ˆì‹œ]
        [{{
        "source_node": {{
            "name": "Triethylene Glycol",
            "alias": ["2,2 ethylenedioxydiethanol", "Ethylene triglycol", "glycol bis (hydroxyethyl) ether", "TEG", "Triglycol"]
        }},
        "target_node": {{
            "name": "SHELL EASTERN CHEMICALS (S) A",
            "alias": ["SHELL EASTERN TRADING (PTE) LTD", "Shell Eastern Chemicals"]
        }},
        "relationship_description": "ì œì¡° ë˜ëŠ” ê³µê¸‰í•œë‹¤",
        "confidence": 0.97
        }}]
        """

        self.PROMPT_FOR_NODES = """ë‹¹ì‹ ì€ RAGì˜ Knowledge Graphë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´, ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ ì£¼ìš”ê°œë…ì„ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ JSON í˜•ì‹ì„ ë”°ë¼ ì£¼ìš”ê°œë…ì„ ì¶”ì¶œí•˜ì„¸ìš”.

        [ë‹µë³€í˜•ì‹]
        [{{
            "name": "ì£¼ìš”ê°œë…ì˜ ì´ë¦„",
            "alias": ["ì£¼ìš”ê°œë…ì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹1", "ì£¼ìš”ê°œë…ì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹2", ...]
            "confidence": ì¶”ì¶œ ê²°ê³¼ì˜ ì‹ ë¢°ë„ (0ê³¼ 1 ì‚¬ì´ì˜ ê°’)
        }}]

        ìœ„ì— ì œì‹œëœ ë‹µë³€ JSON í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ì£¼ì˜ì‚¬í•­ì„ ë”°ë¼ ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ ì£¼ìš”ê°œë…ì„ ì¶”ì¶œí•˜ì„¸ìš”.

        1. ì§ˆë¬¸ì—ì„œ ì¤‘ìš”í•œ ì£¼ìš”ê°œë…(ëª…ì‚¬, ê°œë…, ë¬¼ì§ˆëª…, í™”í•™ë¬¼ì§ˆ, ì¡°ì§, ì¸ë¬¼ ë“±)ë¥¼ ëª¨ë‘ ì¶”ì¶œí•˜ì„¸ìš”.
        2. ë¬¸ì„œ ë‚´ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš”ê°œë…ì˜ ë‹¤ë¥¸ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹ì´ ë“±ì¥í•œë‹¤ë©´ í•¨ê»˜ ì¶”ì¶œí•˜ê³ , alias í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ê°’ì´ ì—¬ëŸ¬ê°œë¼ë©´ ë¬¸ìì—´ ë°°ì—´ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”. ë‹¨, ë¬¸ì„œ ë‚´ì— ë‹¤ë¥¸ í‘œí˜„ ë°©ì‹ì´ ë“±ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì¶”ì¶œí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ë‹¤ë¥¸ í‘œí˜„ ë°©ì‹ì´ 1ê°œì—¬ë„ ë°°ì—´ í˜•íƒœë¡œ ì œì‹œí•˜ì„¸ìš”. (ì˜ˆ: ì—¼ì‚° â†’ ["HYDROCHLORIC ACID"])
        3. ì¶”ì¶œí•œ ì£¼ìš”ê°œë…ì— ëŒ€í•œ ì‹ ë¢°ë„ë¥¼ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ê³„ì‚°í•˜ê³ , confidence í‚¤ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. ì†Œìˆ˜ì ì€ ìµœëŒ€ 10ìë¦¬ê¹Œì§€ë§Œ ì œì‹œí•˜ì„¸ìš”. ë¬¼ë¡ , ì†Œìˆ˜ì  ë°‘ ìë¦¬ê°€ 10ìë¦¬ ë³´ë‹¤ ì ë‹¤ë©´ 10ìë¦¬ë¥¼ ì±„ìš°ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì œì‹œí•˜ì„¸ìš”.
        4. ë‹µë³€ì—ëŠ” ë‹µë³€í˜•ì‹ì¸ JSON ë°°ì—´ì„ ì œì™¸í•œ ê·¸ ì–´ë–¤ ë¬¸êµ¬ë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ì •í™•íˆ ë‹µë³€ JSON ë°°ì—´ë§Œì„ ë‹µë³€í•˜ì„¸ìš”. (ë‹¨, ì£¼ìš”ê°œë…ì´ í•˜ë‚˜ì—¬ë„ ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.)

        [ì£¼ìš”ê°œë…ì„ ì¶”ì¶œí•´ì•¼ í•  ë¬¸ìì—´]
        {text_to_analyze}

        [ë‹µë³€ ì˜ˆì‹œ]
        [{{
            "name": "SHELL EASTERN CHEMICALS (S)",
            "alias": ["SHELL EASTERN TRADING (PTE) LTD", "Shell Eastern Chemicals", "SHELL EASTERN CHEMICALS"],
            "confidence": 0.98
        }}]
        """


    def close(self):
        """
        Neo4j ë“œë¼ì´ë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
        - ë“œë¼ì´ë²„ ì¢…ë£Œí•´ë„ ë°ì´í„°ëŠ” ë³´ì¡´ë©ë‹ˆë‹¤.
        - ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ ìœ„í•´, í•œ íŒŒì´í”„ ë¼ì¸ì—ì„œ ì‚¬ìš©ì´ ì¢…ë£Œë˜ë©´ ë°˜ë“œì‹œ close() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•´ì£¼ì„¸ìš”.
        """
        self.neo4j_driver.close()
        print("â˜‘ï¸ Neo4j driver successfully closed.")


    async def _async_extract_nodes_or_relationships(self, semaphore: asyncio.Semaphore, text_to_analyze: str, need_relationships: bool) -> list[dict[str, Any]]:
        """
        ì£¼ì–´ì§„ ë¬¸ìì—´ì—ì„œ ë…¸ë“œ ë˜ëŠ” ê´€ê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            text_to_analyze(str): ë…¸ë“œ ë˜ëŠ” ê´€ê³„ë¥¼ ì¶”ì¶œí•´ì•¼í•  ë¬¸ìì—´
            need_relationships(bool):
                - True: ë…¸ë“œì™€ ê´€ê³„ ëª¨ë‘ ì¶”ì¶œ (ì²­í¬ë¥¼ neo4jì— ì €ì¥í•  ë•Œ ì‚¬ìš©)
                - False: ë…¸ë“œë§Œ ì¶”ì¶œ (ì¿¼ë¦¬ë¥¼ ë°›ì•„ì„œ ê·¸ë˜í”„ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©)

        Returns:
            list[dict[str, Any]]: ë…¸ë“œì™€ ê´€ê³„ ëª©ë¡
        """

        if need_relationships:
            prompt = self.PROMPT_FOR_NODES_AND_RELATIONSHIPS.format(text_to_analyze=text_to_analyze)
        else:
            prompt = self.PROMPT_FOR_NODES.format(text_to_analyze=text_to_analyze)

        async with semaphore:
            def sync_request():
                url = f"{self.RUNPOD_URI}/api/generate"
                payload = {"model": self.RUNPOD_LLM_MODEL, "prompt": prompt, "stream": False}
                headers = {"Content-Type": "application/json"}
                timeout = float(self.TIMEOUT) if self.TIMEOUT else None
                return requests.post(url, json=payload, headers=headers, timeout=timeout)

            try:
                response = await asyncio.to_thread(sync_request)
                content_type = response.headers.get("Content-Type", "")

                if "application/json" in content_type:
                    raw_data = response.json()
                    data = raw_data['response']
                    print(f"ğŸ” [async_extract_nodes_or_relationships] LLM response: {json.loads(data)}")
                    return json.loads(data)
                else:
                    raw_data = response.text
                    print(f"âš ï¸ [async_extract_nodes_or_relationships] LLM Message: {raw_data}")
                    return raw_data

            except Exception as e:
                print(f"âŒ [async_extract_nodes_or_relationships] LLM async request failed: {e}")
                return []

    
    async def async_ingest_chunks(self, chunks: list[dict]) -> bool:
        """
        ì²­í¬ë“¤ì„ ì§ì ‘ ë§¤ê°œê°’ìœ¼ë¡œ ë°›ê³  chunk ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë…¸ë“œ/ê´€ê³„ë¥¼ ìƒì„±í•˜ì—¬ Neo4jì— MERGE í•©ë‹ˆë‹¤.

        Args:
            chunks(list[dict]): ì²­í¬ ë°°ì—´

        Returns:
            bool: í•˜ë‚˜ ì´ìƒì˜ chunkê°€ ì •ìƒ ì €ì¥ë˜ë©´ True, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ False
        """

        if not chunks:
            print("âš ï¸ [async_ingest_chunks] No chunks provided.")
            return False

        extract_success_count = 0  # ì¶”ì¶œì— ì„±ê³µí•œ
        extract_fail_count = 0  # ì¶”ì¶œì— ì‹¤íŒ¨í•œ
        save_success_count = 0  # ì €ì¥ì— ì„±ê³µí•œ
        save_fail_count = 0  # ì €ì¥ì— ì‹¤íŒ¨í•œ

        semaphore = asyncio.Semaphore(self.MAX_CONCURRENT)

        tasks = []
        for chunk in chunks:
            if chunk.get("type") in {"text", "table"}:
                text_to_analyze = chunk.get("content", "")
            else:
                text_to_analyze = chunk.get("metadata", "")

            if not text_to_analyze:
                print("âš ï¸ [async_ingest_chunks]Skipping chunk with empty content.")
                continue

            tasks.append(self._async_extract_nodes_or_relationships(semaphore, text_to_analyze, True))

        print(f"ğŸš€ [async_ingest_chunks] Sending {len(tasks)} LLM requests concurrently... (max concurrent: {self.MAX_CONCURRENT})")
        print(f"ğŸ” [async_ingest_chunks] LLM responses received. Inserting into Neo4j...")

        all_chunks_nodes_and_relationships = await asyncio.gather(*tasks, return_exceptions=True)

        for i, result in enumerate(all_chunks_nodes_and_relationships):
            if isinstance(result, Exception):
                print(f"âŒ [async_ingest_chunks] Task {i} failed with error: {result}")
                extract_fail_count += 1
            else:
                print(f"âœ… [async_ingest_chunks] Task {i} succeeded, got {len(result)} relationships")
                extract_success_count += 1

        for chunk_nodes_and_relationships in all_chunks_nodes_and_relationships:  # ë°”ê¹¥ list forë¬¸ ëŒë©´ list í•˜ë‚˜ì”© ë‚˜ì˜´!
            if not isinstance(chunk_nodes_and_relationships, list):
                continue

            for nodes_and_relationship in chunk_nodes_and_relationships:  # ê·¸ listëŠ” dictì˜ ë°°ì—´ì´ê¸° ë•Œë¬¸ì—, ë˜ ë°˜ë³µë¬¸ ëŒë©´ dictê°€ í•˜ë‚˜ì”© ë‚˜ì˜´!
                relation_description = nodes_and_relationship.get("relationship_description")

                if not relation_description:
                    print("âš ï¸ [async_ingest_chunks] Skipping relationship without description.")
                    continue

                try:
                    self.neo4j_driver.execute_query(
                        f"""
                        MERGE (source:Entity {{name: $source_name}})
                        ON MATCH SET source.alias = apoc.coll.toSet(COALESCE(source.alias, []) + $source_alias)
                        ON CREATE SET source.alias = $source_alias

                        MERGE (target:Entity {{name: $target_name}})
                        ON MATCH SET target.alias = apoc.coll.toSet(COALESCE(target.alias, []) + $target_alias)
                        ON CREATE SET target.alias = $target_alias
                        
                        MERGE (source)-[r:`%s`]->(target)
                        ON MATCH SET r.confidence = CASE 
                                WHEN r.confidence < $confidence 
                                THEN $confidence 
                                ELSE r.confidence 
                            END,
                            r.file_info = COALESCE(r.file_info, {{}}) + $file_info
                        ON CREATE SET r.confidence = $confidence, r.file_info = $file_info
                        """
                        % relation_description,
                        source_name=nodes_and_relationship["source_node"]["name"],
                        source_alias=nodes_and_relationship["source_node"].get("alias", []),
                        target_name=nodes_and_relationship["target_node"]["name"],
                        target_alias=nodes_and_relationship["target_node"].get("alias", []),
                        confidence=float(nodes_and_relationship["confidence"]),
                        file_info=json.dumps(chunk.get("file_info", {})),
                        database_="neo4j"  # ë¬´ë£Œ ë²„ì „ì€ ì´ë¦„ì´ neo4jì¸ ë°ì´í„°ë² ì´ìŠ¤ í•˜ë‚˜ë§Œ ì‚¬ìš© ê°€ëŠ¥
                    )
                    save_success_count += 1

                except Neo4jError as e:
                    print(f"âŒ [async_ingest_chunks] Failed to insert into Neo4j : {e.__cause__}")
                    print(f"âŒ [async_ingest_chunks] Failed to insert into Neo4j (Detail...) : {e}")
                    save_fail_count += 1
                    continue

        if save_success_count > 0:
            print(f"âœ… [async_ingest_chunks] Successfully extracted {extract_success_count}/{extract_success_count + extract_fail_count} from chunks.")
            print(f"âœ… [async_ingest_chunks] Successfully inserted {save_success_count}/{save_success_count + save_fail_count} relationships into Neo4j.")
            return True
        else:
            print("âŒ [async_ingest_chunks] No relationships were inserted into Neo4j.")
            return False

    
    async def async_search_graph(self, query: str) -> list[dict[str, Any]]:

        semaphore = asyncio.Semaphore(self.MAX_CONCURRENT)
        nodes = await self._async_extract_nodes_or_relationships(semaphore, query, False)
        confidence_results = []

        for node in nodes:
            try:
                records, summary, keys = self.neo4j_driver.execute_query(
                    """
                    MATCH (source:Entity)-[r]-(target:Entity)
                    WHERE source.name = $node_name
                        OR ANY(alias_item IN source.alias WHERE alias_item = $node_name)
                        OR target.name = $node_name
                        OR ANY(alias_item IN target.alias WHERE alias_item = $node_name)
                    RETURN
                        source.name AS source,
                        target.name AS target,
                        type(r) AS relationship_description,
                        r.confidence AS confidence,
                        r.file_info AS file_info
                    """,
                    node_name=node['name'],
                    database_="neo4j"
                )
            except Neo4jError as e:
                print(f"âŒ [async_search_graph] Failed to search graph(Neo4jError): {e.__cause__}")
                continue

            except Exception as e:
                print(f"âŒ [async_search_graph] Failed to search graph: {e}")
                continue

            for record in records:
                confidence_results.append({
                    "graph": record["source"] + " - " + record["relationship_description"] + " -> " + record["target"],
                    "file_info": json.loads(record["file_info"]),
                    "confidence": float(record["confidence"])
                })

        confidence_results.sort(key=lambda x: x["confidence"], reverse=True) # confidence ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        confidence_results = confidence_results[:5]

        results = [] # confidence í‚¤ ì—†ì•¤ results
        for confidence_result in confidence_results:
            results.append({
                "graph": confidence_result["graph"],
                "file_info": confidence_result["file_info"]
            })

            print("ğŸ” [async_search_graph] Results:")
            print(f"graph: {confidence_result['graph']}")
            print(f"file Info: {confidence_result['file_info']}")
            print(f"confidence: {confidence_result['confidence']}")

        return results

    async def generate_answer(self, query: str) -> str:
            """
            ë‹µë³€ìƒì„±
            """

            results = await self.async_search_graph(query)

            prompt = f"""
            ë‹¹ì‹ ì€ ì‚¼ì„±ì „ì ìƒì‚°ê¸°ìˆ ì—°êµ¬ì†Œì˜ ì†Œì¬ ë¬¼ì„± ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ê·¼ê±° ì¤‘ì‹¬ì˜ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
            ë‹¹ì‹ ì˜ ëª¨ë“  ë‹µë³€ì€ ì•„ë˜ ì œê³µëœ ë¬¸ì„œ(JSON í˜•íƒœ)ì˜ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤. 
            ì¶”ë¡ ì„ í•  ë•Œë„ ë°˜ë“œì‹œ ë¬¸ì„œì˜ ë‚´ìš©ì„ ê·¼ê±°ë¡œ í•´ì•¼ í•˜ë©°, ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ê³  ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”.
            -----------------------------
            [ì‚¬ìš©ì ì§ˆë¬¸]
            {query}
            -----------------------------
            [ê·¸ë˜í”„ ê²€ìƒ‰ ê²°ê³¼]
            {results}
            -----------------------------
            [ì§€ì¹¨]
            1. ë°˜ë“œì‹œ ë¬¸ì„œ(JSON) ì† text ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
            2. ë‹µë³€ì—ëŠ” ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
            (A) ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•œ ë‹µë³€
            (B) ë‹µë³€ì— ì‚¬ìš©ëœ ê·¼ê±°ì˜ ì¶œì²˜ (file_uuid(íŒŒì¼ ê³ ìœ  UUID), file_name(íŒŒì¼ëª…), page_num(í˜ì´ì§€ ë²ˆí˜¸), collections(ì²­í¬ ì»¬ë ‰ì…˜ ì´ë¦„))
            3. ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ì°¸ì¡°í–ˆë‹¤ë©´ ì¶œì²˜ë¥¼ ëª¨ë‘ í‘œê¸°í•˜ì„¸ìš”.
            4. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” "ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”. ì´ë•Œì—ëŠ” file_infoì— ëŒ€í•œ ë‚´ìš©ì„ ë¹„ì›Œë‘ì„¸ìš”.
            5. JSON ì•ˆì˜ êµ¬ì¡°(key ì´ë¦„)ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
            6. image / link íƒ€ì… chunkëŠ” metadataë¥¼ ìš”ì•½í•´ í…ìŠ¤íŠ¸ì²˜ëŸ¼ ë‹¤ë¤„ë„ ë©ë‹ˆë‹¤.
            -----------------------------
            [ì¶œë ¥ í˜•ì‹]
            ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:

            {{
                "answer" : "ë‹µë³€",
                "file_info" : {{
                    "file_uuid" : "ë°±ì—”ë“œì—ì„œ ë„˜ì–´ì˜¤ëŠ” Doc ID",
                    "file_name" : "íŒŒì¼ ì´ë¦„",
                    "page_num" : í˜ì´ì§€ ë²ˆí˜¸ ì •ìˆ˜ ë°°ì—´,
                    "collections" : ì²­í¬ê°€ ì†í•œ ì»¬ë ‰ì…˜ ì´ë¦„ ë°°ì—´
                }}
            }}
            """

            # ë‹µë³€ ìš”ì²­
            url = f"{self.RUNPOD_URI}/api/generate"
            payload = {"model": self.RUNPOD_LLM_MODEL, "prompt": prompt, "stream": False}
            timeout = float(self.TIMEOUT) if self.TIMEOUT else None
            response = requests.post(url, json=payload, timeout=timeout)

            try:
                response.raise_for_status() # ì—ëŸ¬ë©´ ì˜ˆì™¸ë°œìƒ
            except requests.RequestException as e:
                print(f"HTTP request failed: {e}")

            print(f"ğŸ” [generate_answer] LLM response: {response.json()['response']}")
            return response.json()['response']


async def main():
    """
    Neo4jKnowledgeGraph í†µí•´ ê·¸ë˜í”„ ì €ì¥ ë° ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.
    ë¨¼ì € í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì€ md ë¬¸ì„œì˜ ì²­í‚¹ì„ ì™„ë£Œí•œ í›„ì— ì‹¤í–‰í•´ì£¼ì„¸ìš”.
    """
    from retriever.chunker.markdown_chunker import MarkdownChunker


    BASE_DIR = Path(__file__).resolve().parents[2]  # root ê²½ë¡œ
    markdown_sample_data_folder_path = BASE_DIR / "retriever" / "markdown_sample_data" # markdown ìƒ˜í”Œ ë°ì´í„° ê²½ë¡œ

    print("ğŸ“‚ Searching md files in:", markdown_sample_data_folder_path)

    for markdown_file_path in markdown_sample_data_folder_path.rglob("*.md"): # md íŒŒì¼ë§Œ ìˆœíšŒëŒê¸°
        with open(markdown_file_path, "r", encoding="utf-8") as f:  # íŒŒì¼ë¡œë¶€í„° md ë¬¸ìì—´ì„ ì½ì–´ì˜µë‹ˆë‹¤.
            md = f.read()

            markdown_chunker = MarkdownChunker()

            chunks = markdown_chunker.chunk_markdown_file(md, "5bc0c676-018f-46de-bb0d-0103ff9c388c", "5bc0c676-018f-46de-bb0d-0103ff9c388c_3M-1509-DC-Polyethylene-Tape-TIS-Jun13", ["msds"])

            knowledge_graph = Neo4jKnowledgeGraph()
            await knowledge_graph.async_ingest_chunks(chunks)

            # knowledge_graph.async_search_graph("ISA KitëŠ” ë¬´ì—‡ì„ í…ŒìŠ¤íŠ¸í•˜ë‚˜ìš”?") # ê²€ìƒ‰ ëŒ€ìƒì¸ ë¬¸ì„œì— ëŒ€í•œ ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”
            await knowledge_graph.generate_answer("ì•„ì„¸í†¤ì˜ ê¶Œê³ ìš©ë„ëŠ”?")
            knowledge_graph.close()

if __name__ == "__main__":
    asyncio.run(main())