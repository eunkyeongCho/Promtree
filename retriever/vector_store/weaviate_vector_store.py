import weaviate
from weaviate.classes.config import (
    Configure,
    Property,
    DataType,
    Tokenization,
    VectorDistances,
    VectorFilterStrategy
)
import weaviate.classes as wvc
from weaviate.classes.query import (
    HybridFusion,
    BM25Operator,
    MetadataQuery
)
from weaviate.classes.init import Auth, Timeout
from sentence_transformers import SentenceTransformer

from retriever.vector_store.base_vector_store import BaseVectorStore


class WeaviateVectorStore(BaseVectorStore):

    # Weaviateì—ì„œ DB Tableì— í•´ë‹¹í•˜ëŠ” ê°œë…ì´ Collection
    # ì´ë¦„ì„ ì§€ì •í•´ì¤˜ì•¼ í•˜ëŠ”ë°, ì¼ë‹¨ì€ MaterialPropertyKnowledgeìœ¼ë¡œ í•˜ë“œì½”ë”©í•˜ê³  ì¶”í›„ì— í™•ì¥ì´ í•„ìš”í•˜ë‹¤ë©´ Initializerì—ì„œ ë°›ë„ë¡ ìˆ˜ì •í•  ì˜ˆì •
    collection_name = "MaterialPropertyKnowledge"

    def __init__(self, cluster_url: str, api_key: str) -> None:

        # Qwen ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        self.model = SentenceTransformer('Qwen/Qwen3-Embedding-0.6B', trust_remote_code=True)

        # client ìƒì„±
        self.client = weaviate.connect_to_weaviate_cloud(
            cluster_url = cluster_url,
            auth_credentials = Auth.api_key(api_key)
        )
        self.client.timeout_config = Timeout(connect=10, read=60)
        
        is_client_connected = self.client.is_ready()

        if is_client_connected:
            print("âœ… Successfully connected to Weaviate Cloud.")
        else:
            raise ConnectionError(
                "âŒ Failed to connect to Weaviate Cloud. "
                "Please check your cluster URL, API key, and network configuration."
            )

        # Collection ìƒì„±
        if not self.client.collections.exists(self.collection_name):
            self.client.collections.create(
                name=self.collection_name,
                properties=[ # Property ì •ì˜ (Columnê³¼ ê°™ì€ ê°œë…)
                    Property(
                        name="type",
                        data_type=DataType.TEXT,
                        tokenization=Tokenization.LOWERCASE, # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œ ì˜ì–´ëŠ” ëª¨ë‘ ì†Œë¬¸ìë¡œ ë°”ê¿”ì„œ ê³µë°± ê¸°ì¤€ ë‚˜ëˆ ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ì— ì‚¬ìš©
                        description="ì›ë³¸ Chunk íƒ€ì…"
                    ),
                    Property(
                        name="content",
                        data_type=DataType.TEXT,
                        tokenization=Tokenization.LOWERCASE, # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œ ì˜ì–´ëŠ” ëª¨ë‘ ì†Œë¬¸ìë¡œ ë°”ê¿”ì„œ ê³µë°± ê¸°ì¤€ ë‚˜ëˆ ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ì— ì‚¬ìš©
                        description="ì›ë³¸ Chunk ë‚´ìš©"
                    ),
                    Property(
                        name="metadata",
                        data_type=DataType.TEXT,
                        description="ì›ë³¸ Chunk ë©”íƒ€ë°ì´í„°"
                    ),
                    Property(
                        name="file_info",
                        data_type=DataType.OBJECT,
                        description="ì›ë³¸ Chunk íŒŒì¼ ê´€ë ¨ ì •ë³´",
                        nested_properties=[
                            Property(name="file_uuid", data_type=DataType.TEXT),
                            Property(name="file_name", data_type=DataType.TEXT),
                            Property(name="collections", data_type=DataType.TEXT_ARRAY),
                            Property(name="page_num", data_type=DataType.INT_ARRAY),
                        ],
                    )
                ],
                vector_config=wvc.config.Configure.Vectors.self_provided(
                    vector_index_config=wvc.config.Configure.VectorIndex.hnsw( # HNSW ì¸ë±ìŠ¤ ì‚¬ìš©
                        ef_construction=300, # ì¸ë±ìŠ¤ë¥¼ ë§Œë“¤ ë•Œ ì‚¬ìš©í•˜ëŠ” íƒìƒ‰ ë„ˆë¹„(ê°’ì´ í´ìˆ˜ë¡ ê²€ìƒ‰ ì •í™•ë„ ì¦ê°€ ë° ê²€ìƒ‰ ì‹œê°„ ì¦ê°€, 100-300ì´ ê¸°ë³¸ê°’)
                        distance_metric=VectorDistances.COSINE, # ë²¡í„°ê°„ ìœ ì‚¬ë„ ê³„ì‚° ë°©ì‹ (í…ìŠ¤íŠ¸ ê¸°ë°˜ RAGëŠ” COSINE ê¶Œì¥)
                        filter_strategy=VectorFilterStrategy.ACORN, # ê²€ìƒ‰ ì‹œ í•„í„°ì™€ ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ì–´ë–»ê²Œ ê²°í•©í•´ì„œ ê²€ìƒ‰í• ì§€ ê²°ì •. (ACORNì€ í•„í„°ì™€ ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ê²°í•©í•´ì„œ ì†ë„ê°€ ê°œì„ ëœ ìµœì‹  ê¸°ë²•)
                    )
                ), # ì™¸ë¶€ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©í•´ì„œ ì„ë² ë”©ì„ í•˜ì§€ ì•ŠìŒ
                inverted_index_config=Configure.inverted_index( # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œ ì†ë„ ë° ì •ë°€ë„ í–¥ìƒì„ ìœ„í•´ í•´ë†“ëŠ” ì—­ìƒ‰ì¸ì„ ìœ„í•œ ì„¤ì •ë“¤ (í˜„ì¬ëŠ” ì „ë¶€ ê³µì‹ë¬¸ì„œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •)
                    bm25_b=0.7, # ë¬¸ì¥ê¸¸ì´ê°€ ê¸¸ìˆ˜ë¡ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ ì¦ê°€í•˜ë¯€ë¡œ ë¬¸ì¥ê¸¸ì´ì— ë”°ë¥¸ ì˜í–¥ë„ë¥¼ ì¡°ì ˆí•˜ê¸° ìœ„í•œ íŒŒë¼ë¯¸í„° (ë†’ì„ìˆ˜ë¡ ì§§ì€ ë¬¸ì¥ì— ëŒ€í•´ ê°€ì¤‘ì¹˜ë¥¼ ì¤Œ)
                    bm25_k1=1.25, # ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ê°€ì¤‘ì¹˜ë¥¼ ì¤„ì§€ì— ëŒ€í•œ íŒŒë¼ë¯¸í„° (ë†’ì„ìˆ˜ë¡ ë¹ˆë„ìˆ˜ê°€ ë†’ì€ ê²ƒì— ëŒ€í•´ ê°€ì¤‘ì¹˜ë¥¼ ì¤Œ)
                    index_null_state=True, # NULL ê°’ì„ ì¸ë±ì‹±í•˜ì—¬ í•„í„°ë§ì— í™œìš©í• ì§€ ì—¬ë¶€ (True: í¬í•¨, False: ì œì™¸)
                    index_property_length=True, # ì†ì„± ê¸¸ì´ë¥¼ ì¸ë±ì‹±í•˜ì—¬ í•„í„°ë§ì— í™œìš©í• ì§€ ì—¬ë¶€ (True: í¬í•¨, False: ì œì™¸)
                    index_timestamps=True, # ìƒì„±/ì—…ë°ì´íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ë¥¼ ì¸ë±ì‹±í• ì§€ ì—¬ë¶€ (True: ìµœì‹ ìˆœ ì •ë ¬/ê¸°ê°„ ê²€ìƒ‰ ê°€ëŠ¥, False: ë¶ˆê°€ëŠ¥)
                )
            )

    def add_documents(self, chunks: list[dict]) -> bool:
        """
            Document ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•˜ì—¬ Weaviate ì»¬ë ‰ì…˜ì— ì¼ê´„ ì €ì¥í•©ë‹ˆë‹¤.

            ì£¼ì–´ì§„ Documentì—ì„œ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³ , ë§¤ê°œê°’ìœ¼ë¡œ ë°›ì€ ì„ë² ë”© ëª¨ë¸ë¡œ ë²¡í„°ë¥¼ ìƒì„±í•œ ë’¤ batch ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
            batch ì €ì¥ì€ ê°œë³„ ì—…ë¡œë“œë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê²Œ ë™ì‘í•©ë‹ˆë‹¤.

            Args:
                documents (list[Document]): ì €ì¥í•  Document ëª©ë¡. (LangChain Core Documentíƒ€ì…ì˜ ë°°ì—´)
                embedding_model (BaseEmbeddingModel): ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸

            Returns:
                bool: ì €ì¥ ì™„ë£Œ ì‹œ True.
        """

        types = [chunk.get('type') for chunk in chunks]
        contents = [chunk.get('content') for chunk in chunks]
        metadatas = [chunk.get('metadata') for chunk in chunks]
        file_infos = [chunk.get('file_info') for chunk in chunks]

        vectors = []
        for chunk in chunks:
            chunk_type = chunk.get('type')
            content = chunk.get('content', "")
            metadata = chunk.get('metadata', "")
            if chunk_type in ("text", "table"):
                vectors.append(self.model.encode(content, normalize_embeddings=True, show_progress_bar=True))
            else:
                vectors.append(self.model.encode(metadata, normalize_embeddings=True, show_progress_bar=True))

        print("ğŸ“Œ Generated vectors (preview only first 10 dims):")

        with self.client.batch.dynamic() as batch: # fixed_size(), rate_limit()ë„ ì‚¬ìš©ê°€ëŠ¥
            for i, (type, content, metadata, file_info, vector) in enumerate(zip(types, contents, metadatas, file_infos, vectors), 1):
                print(f"\nğŸ§© Chunk #{i + 1}")
                print(f" - type: {type}")
                print(f" - content: {content}")
                print(f" - metadata: {metadata}")
                print(f" - file_info: {file_info}")
                print(f" - vector[:10]: {vector[:10]}")

                batch.add_object(
                    collection=self.collection_name,
                    properties={
                        "type": type,
                        "content": content,
                        "metadata": metadata,
                        "file_info": file_info
                    },
                    vector=vector,
                )

        print(f"âœ… Successfully stored vectorized documents into the '{self.collection_name}' collection.")
        print("â„¹ï¸  When you have finished all Weaviate-related operations, call `close()` to safely close the client connection.")

        return True

    def similarity_search(self, query: str) -> list[dict]:
        """
            ë¹„êµí•´ì„œ ê²€ìƒ‰í•  ë¬¸ìì—´ì— ëŒ€í•´ ì„ë² ë”©ì„ ìƒì„±í•œ í›„, Weaviateì—ì„œ ìœ ì‚¬ ë¬¸ì„œë¥¼ ë²¡í„° ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.

            Args:
                information_need (str): ê²€ìƒ‰ ì§ˆì˜ ë¬¸ìì—´
                embedding_model (BaseEmbeddingModel): ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸

            Returns:
                list[Document]: ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ëœ Document ë¦¬ìŠ¤íŠ¸
        """

        print(f"\nğŸ” [SIMILARITY SEARCH] Query: '{query}'")

        # information_need ë²¡í„°í™”
        query_vector = self.model.encode(query, normalize_embeddings=True, show_progress_bar=True)
        print("âœ… Query vector generated. (preview first 10 dims):", query_vector[:10])

        # Collection ê°ì²´ ê°€ì ¸ì˜¤ê¸°
        if self.client.collections.exists(self.collection_name):
            collection = self.client.collections.use(self.collection_name)
        else:
            raise ValueError(
                f"âŒ Collection '{self.collection_name}' does not exist. "
                f"Please ensure that the WeaviateVectorStore is properly initialized and that the collection has been created."
            )

        print(f"\nğŸ“‚ Using collection: {self.collection_name}")
        print("ğŸ” Running hybrid search...")

        # ê²€ìƒ‰ ìˆ˜í–‰
        # search_result = collection.query.hybrid( # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°ë²• ì‚¬ìš©
        #     query=query,
        #     vector=query_vector,
        #     fusion_type=HybridFusion.RANKED, # í‚¤ì›Œë“œ ê²€ìƒ‰ ì ìˆ˜ì™€ ë²¡í„° ê²€ìƒ‰ ì ìˆ˜ë¥¼ ì •ê·œí™”í•˜ì§€ ì•Šê³  ìˆœìœ„ì—ë§Œ ê¸°ë°˜í•´ì„œ ê²€ìƒ‰. (RELATIVE_SCOREë„ ì„ íƒ ê°€ëŠ¥í•œë° ì†Œì¬ ë¬¼ì„± ìª½ì€ RANKEDê°€ ë” ì•ˆì •ì ì¸ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¨ë‹¤ê³  í•¨) 
        #     bm25_operator=BM25Operator.or_(minimum_match=2), # ì¿¼ë¦¬ì˜ í‚¤ì›Œë“œ ìµœì†Œ 2ê°œ ì´ìƒ í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•¨ (ê¸°ë³¸ ì¶”ì²œê°’)
        #     alpha=0.5, # ì†Œì¬ ë¬¼ì„±ì„ ë‹¤ë£¨ë¯€ë¡œ ë‹¤ë¥¸ ë„ë©”ì¸ ë³´ë‹¤ í‚¤ì›Œë“œê°€ ì¢€ ë” ì¤‘ìš”í•œ ê²½í–¥ì´ ìˆì–´ì„œ ê¸°ë³¸ ì¶”ì²œê°’ì¸ 0.75ë³´ë‹¤ ì¢€ ë” í‚¤ì›Œë“œ ê²€ìƒ‰ì— ë¹„ì¤‘ì„ ë‘ëŠ” 0.5 ì •ë„ë¡œ ì„¤ì •
        #     limit=50, # í›„ì— mmr, reranking ë‹¨ê³„ì—ì„œ í›„ì²˜ë¦¬ë¥¼ í•˜ë¯€ë¡œ hybrid search ë‹¨ê³„ì—ì„œëŠ” ë„‰ë„‰í•˜ê²Œ 50ê°œ ê°€ì ¸ì˜¤ê¸°
        #     # max_vector_distanceì€ ì¼ë°˜ì ìœ¼ë¡œ ê¸°ìˆ ì ì¸ ë¬¸ì„œëŠ” ìœ ì˜ë¯¸í•œ ê²°ê³¼ê°’ë„ ë²¡í„° ê³µê°„ ìƒì—ì„œëŠ” ë©€ê²Œ í‘œí˜„ë˜ëŠ” ê²½ìš°ê°€ ìˆì–´ì„œ ì˜ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” íŒŒë¼ë¯¸í„°ë¼ê³  í•´ì„œ ì¼ë‹¨ ì œì™¸
        #     return_metadata=MetadataQuery(score=True, explain_score=True) # scoreì™€ ê·¸ì— ëŒ€í•œ ì„¤ëª… ë°›ê¸°
        # )

        search_results = self.client.collections.use(self.collection_name).query.near_vector(
            near_vector=query_vector, # your query vector goes here
            limit=10,
            return_metadata=MetadataQuery(distance=True)
        )

        print(f"âœ… Vector search complete. Retrieved {len(search_results.objects)} chunks.\n")

        scored_results = []
        for obj in search_results.objects:
            scored_results.append({
                "score": obj.metadata.distance,
                "explain_score": None,
                "type": obj.properties['type'],
                "content": obj.properties['content'],
                "metadata": obj.properties['metadata'],
                "file_info": obj.properties['file_info']
            })

        sorted_results = sorted(scored_results, key=lambda x: x["score"], reverse=True)

        return sorted_results

    def close(self):
        self.client.close()