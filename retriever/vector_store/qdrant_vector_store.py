from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient

from typing import List
import numpy as np
import json

def init():
    """
    ëª¨ë¸ê³¼ client ì—°ê²° ì´ˆê¸°í™”
    """
    # Qwen ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    model = SentenceTransformer('Qwen/Qwen3-Embedding-0.6B', trust_remote_code=True)

    # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = QdrantClient(url="http://localhost:6333")

    return model, client

def query_embedding(model: SentenceTransformer, text: str) -> List[float]:
    """
    ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜

    Args:
        model: SentenceTransformer ëª¨ë¸
        text: ì¿¼ë¦¬ í…ìŠ¤íŠ¸
    Returns:
        ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
    """
    embedding = model.encode([text], normalize_embeddings=True)
    return embedding[0]


def search_similar_chunks(client: QdrantClient, qv, collections: list[str], top_k=5) -> list[dict]:
    """
    ì—¬ëŸ¬ Qdrant ì»¬ë ‰ì…˜ì„ ëŒ€ìƒìœ¼ë¡œ ì¿¼ë¦¬ ë²¡í„°ì™€ ìœ ì‚¬í•œ ì²­í¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì»¬ë ‰ì…˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° ê° ì»¬ë ‰ì…˜ì— ëŒ€í•´ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³ ,
    ê²€ìƒ‰ëœ ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ìë‹ˆë‹¤. ì´í›„ ìœ ì‚¬ë„(score) ê¸°ì¤€ìœ¼ë¡œ
    ì „ì²´ ê²°ê³¼ë¥¼ ì •ë ¬í•˜ì—¬ ìƒìœ„ top_k ê°œë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        client (QdrantClient):
            Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤.
        qv (list[float] ë˜ëŠ” np.ndarray):
            ê²€ìƒ‰ ê¸°ì¤€ì´ ë˜ëŠ” ì¿¼ë¦¬ ë²¡í„°.
        collections (list[str]):
            ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ì»¬ë ‰ì…˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸.
        top_k (int, optional):
            ìµœì¢…ì ìœ¼ë¡œ ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜. ê¸°ë³¸ê°’ì€ 5.

    Returns:
        list[dict]:
            ê° ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸.
            ê° ë”•ì…”ë„ˆë¦¬ëŠ” ë‹¤ìŒ í•„ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
                - "score": ì¿¼ë¦¬ ë²¡í„°ì™€ì˜ ìœ ì‚¬ë„ ì ìˆ˜
                - "chunk": í•´ë‹¹ ì²­í¬ì˜ payload(ë‚´ìš©/ë©”íƒ€ë°ì´í„°)
            ê²°ê³¼ëŠ” score ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ë˜ë©°, ìƒìœ„ top_kê°œë§Œ ë°˜í™˜ë©ë‹ˆë‹¤.
    """
    if isinstance(qv, np.ndarray):
        qv = qv.tolist() # qdrantëŠ” ë‚´ë¶€ì ìœ¼ë¡œ list í˜•íƒœì˜ ë²¡í„°ë¥¼ ê¸°ëŒ€í•˜ê¸° ë•Œë¬¸ì—, listë¡œ ë³€í™˜

    combined_results = []
    
    print(f"\nğŸ” Vector Search Results (Top-{len(results)})\n")

    for collection in collections:
        result = client.query_points(
            collection_name=collection,
            query=qv,
            limit=top_k,
        )

        for r in result.points:
            combined_results.append({
                "score": r.score,
                "chunk": r.payload
            })

    if not combined_results:
        print(f"No results found.")
        return

    combined_results = sorted(combined_results, key=lambda x: x["score"], reverse=True)

    for idx, item in enumerate(combined_results, start=1):
        score = item["score"]
        chunk = item["chunk"]

        try:
            chunk_str = json.dumps(chunk, ensure_ascii=False, indent=2)
        except:
            chunk_str = str(chunk)

        print(f"--- Result {idx} ---")
        print(f"Score: {score:.4f}")
        print(f"Chunk:\n{(chunk_str, '  ')}\n")

    return combined_results[:top_k]

if __name__ == "__main__":
    model, client = init()
    example_query = "Product Number 1509ì˜ ì‹¤í—˜ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì‹œì˜¤"

    qv = query_embedding(model, example_query)
    results = search_similar_chunks(client, qv, collection_name="demo", top_k=2)

    print(f"Query: {example_query}")
    print(f"\n=== ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ {2}ê°œ) ===")

    for idx, point in enumerate(results.points, 1):
        print(f"\n--- ê²°ê³¼ {idx} ---")
        print(f"Score: {point.score:.4f}")
        print(f"Text: {point.payload.get('text', 'N/A')[:200]}...")
        print(f"Chunk Index: {point.payload.get('chunk_index', 'N/A')}")
