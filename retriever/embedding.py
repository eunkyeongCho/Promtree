from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct
from qdrant_client.models import VectorParams, Distance

from typing import List
import uuid
import json


def init():
    """
    ëª¨ë¸ê³¼ client ì—°ê²° ì´ˆê¸°í™”
    """
    # Qwen ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    model = SentenceTransformer('Qwen/Qwen3-Embedding-0.6B', trust_remote_code=True)

    # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = QdrantClient(url="http://localhost:6333")

    return model, client

def chunk_embedding_and_upsert(chunks: List[dict], model: SentenceTransformer, client: QdrantClient, collections: list[str]) -> None:
    """
    ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  Qdrantì— ì—…ë¡œë“œ

    Args:
        chunk: ì²­í¬ ë¦¬ìŠ¤íŠ¸
        model: SentenceTransformer ëª¨ë¸
        client: QdrantClient ì¸ìŠ¤í„´ìŠ¤
        collections: ì‚¬ìš©ìê°€ ì„ íƒí•œ ì»¬ë ‰ì…˜ ë¦¬ìŠ¤íŠ¸
    """

    points = []
    for idx, chunk in enumerate(chunks, 1):
        if chunk['type'] == "text" or chunk['type'] == "table":
            embeddings = model.encode(chunk['content'], normalize_embeddings=True, show_progress_bar=True)
        else:
            embeddings = model.encode(chunk['metadata'], normalize_embeddings=True, show_progress_bar=True)

        print(f"âœ… Embedding chunk {idx}/{len(chunks)}\n")

        point = PointStruct(
            id=str(uuid.uuid4()),
            vector=embeddings,
            payload=chunk
        )

        print(json.dumps({
            "id": point.id,
            "vector_dim": len(point.vector),
            "payload": point.payload
        }, ensure_ascii=False, indent=2))

        points.append(point)

    print("âœ… Embedding completed.\n")

    for collection in collections:
        print(f"ğŸ“Œ Uploading to {collection} collection in Qdrant...\n")
        client.upsert(collection_name=collection, points=points)
    
    print("ğŸ‰ All embeddings successfully uploaded to Qdrant!\n")

if __name__ == "__main__":
    import retriever.chunker.chunking as chunking
    from retriever.chunker.markdown_chunker import MarkdownChunker
    import retriever.parsing as parsing
    from pathlib import Path
    from qdrant_client.models import Distance, VectorParams

    model, client = init()

    # ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì‚­ì œ í›„ ì¬ìƒì„±
    collections = ["msds", "tds"]
    for collection in collections:
        try:
            if client.collection_exists(collection):
                print(f"ì»¬ë ‰ì…˜ '{collection}'ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì‚­ì œ í›„ ì¬ìƒì„±í•©ë‹ˆë‹¤.")
                client.delete_collection(collection)
        except Exception as e:
            print(f"ì»¬ë ‰ì…˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")

        client.create_collection(
            collection_name=collection,
            vectors_config=VectorParams(
                size=1024,
                distance=Distance.COSINE
            )
        )
        print(f"ì»¬ë ‰ì…˜ '{collection}' ìƒì„± ì™„ë£Œ.")

    retriever_dir = Path(__file__).resolve().parent
    pdf_path = retriever_dir / "3M-1509-DC-Polyethylene-Tape-TIS-Jun13.pdf"
    markdown_sample_data_folder_path = retriever_dir / "markdown_sample_data"

    # converter = parsing.converter_init()
    # contents = parsing.parse_pdf(pdf_path, converter)

    markdown_chunker = MarkdownChunker()

    for md_file_path in markdown_sample_data_folder_path.rglob("*.md"): # md íŒŒì¼ë§Œ ìˆœíšŒëŒê¸°

        chunks = markdown_chunker.chunk_markdown_file(md_file_path)

    chunk_embedding_and_upsert(chunks, model, client, ["msds", "tds"])

    # ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ í™•ì¸
    for collection in collections:
        count_result = client.count(collection_name=collection)
        print(f"\n=== ì €ì¥ ì™„ë£Œ ===")
        print(f"ì´ ë²¡í„° ê°œìˆ˜: {count_result.count}")

    # ì €ì¥ëœ ë°ì´í„° ìƒ˜í”Œ í™•ì¸ (ì²˜ìŒ 3ê°œ)
    for collection in collections:
        print(f"\n=== ì €ì¥ëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ) ===")
        scroll_result = client.scroll(
            collection_name=collection,
            limit=3,
            with_payload=True,
            with_vectors=True
        )

    for idx, point in enumerate(scroll_result[0], 1):
        print(f"\n--- ìƒ˜í”Œ {idx} ---")
        print(f"ID: {point.id}")
        print(f"ì²­í¬ ì¸ë±ìŠ¤: {point.payload.get('chunk_index', 'N/A')}")
        print(f"ë²¡í„° ì°¨ì›: {len(point.vector)}")
        print(f"ë²¡í„° ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ): {point.vector[:10]}")
        print(f"ì›ë³¸ í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì):\n{point.payload.get('text', 'N/A')[:200]}...")
