from typing import List, Dict, Any
from elasticsearch import helpers

from db.mongodb import get_mongodb_client
from db.elasticsearch.elasticsearch import get_elasticsearch_client


class ElasticSearchIndexer:
    def __init__(self):
        self.mongo_client = get_mongodb_client()
        self.es_client = get_elasticsearch_client()
        self.chunk_collection = self.mongo_client["chunk_db"]["chunk_collection"]


    def index_file(self, file_name: str, index_name: str) -> bool:

        # MongoDBì—ì„œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        chunks = self.chunk_collection.find({"file_info.file_name": file_name})

        # ì²­í¬ ë°ì´í„°ë¥¼ ëª¨ë‘ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ë©´ ë¹„íš¨ìœ¨ì ì´ë¯€ë¡œ, ì²«ë²ˆì§¸ ì²­í¬ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì²­í¬ ì¡´ì¬ì—¬ë¶€ í™•ì¸
        first_chunk = next(chunks, None)

        if first_chunk is None:
            print(f"âš ï¸ No chunk data found for file: {file_name}")
            return False

        # ì²­í¬ê°€ ì¡´ì¬í•œë‹¤ë©´ ì¸ë±ì‹± ì§„í–‰
        # actionì€ ê³µì‹ë¬¸ì„œì˜ í‘œí˜„ì´ì–´ì„œ ë”°ë¦„
        # ì¸ë±ì‹±í•  ë°ì´í„°ë¥¼ ëª¨ë‘ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ì§€ ì•Šê³ , generatorë¥¼ í†µí•´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì”© í˜ë ¤ë³´ë‚´ëŠ” ê²ƒì´ ê³µì‹ë¬¸ì„œì—ì„œ ê¶Œì¥í•˜ëŠ” ë°©ì‹ì´ë¯€ë¡œ ë”°ë¦„
        def generate_actions():
            # ì²« ë¬¸ì„œë¶€í„° ì²˜ë¦¬
            yield {
                "_op_type": "index",
                "_index": index_name,
                "_id": str(first_chunk["_id"]),
                "_source": {
                    "type": first_chunk.get("type", ""),
                    "content": first_chunk.get("content", ""),
                    "metadata": first_chunk.get("metadata", ""),
                    "file_info": first_chunk.get("file_info", {})
                }
            }

            # ë‚˜ë¨¸ì§€ ë¬¸ì„œ ì²˜ë¦¬
            for chunk in chunks:
                yield {
                    "_op_type": "index",
                    "_index": index_name,
                    "_id": str(chunk["_id"]),
                    "_source": {
                        "type": chunk.get("type", ""),
                        "content": chunk.get("content", ""),
                        "metadata": chunk.get("metadata", ""),
                        "file_info": chunk.get("file_info", {})
                    }
                }

        try:
            (success_count, errors) = helpers.bulk(self.es_client, generate_actions())

        except Exception as e:
            print(f"âŒ Error indexing chunks: {e}")
            return False

        error_count = len(errors) if errors else 0

        print(f"âœ… Indexed {success_count} chunks into `{index_name}` with {error_count} errors.")
        
        if errors and error_count > 0:
            print("\nâš ï¸ Detailed errors:")
            for i, err in enumerate(errors, start=1):
                print(f"  {i}. {err}\n")
        else:
            print("ğŸ‰ No errors during indexing!")

        return True


    def search(self, query: str, index_name: str, size: int = 10) -> List[Dict[str, Any]]:
        """
        Elasticsearchì—ì„œ queryë¡œ ê²€ìƒ‰
        """
        print(f"\nğŸ” Searching index: {index_name} | query: {query}")

        response = self.es_client.search(
            index=index_name,
            size=size,
            query={
                "multi_match": {
                    "query": query,
                    "fields": ["content", "metadata"]   # ë‘˜ ë‹¤ ê²€ìƒ‰
                }
            }
        )

        hits = response["hits"]["hits"]

        # ê²°ê³¼ ë°ì´í„°ë¥¼ ê¹”ë”í•˜ê²Œ ì •ë¦¬
        results = [
            {
                "score": hit["_score"],
                "type": hit["_source"].get("type"),
                "content": hit["_source"].get("content"),
                "metadata": hit["_source"].get("metadata"),
                "file_name": hit["_source"].get("file_info", {}).get("file_name"),
                "page_num": hit["_source"].get("file_info", {}).get("page_num"),
            }
            for hit in hits
        ]

        print(f"âœ… Found {len(results)} results")
        return results
