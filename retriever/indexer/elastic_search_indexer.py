from typing import List, Dict, Any
from elasticsearch import helpers

from db.mongodb import get_mongodb_client
from db.elasticsearch.elasticsearch import get_elasticsearch_client


class ElasticSearchIndexer:
    def __init__(self):
        self.mongodb_client = get_mongodb_client()
        self.elasticsearch_client = get_elasticsearch_client()
        self.chunk_collection = self.mongo_client["chunk_db"]["chunk_collection"]


    def index_file(self, file_name: str, index_name: str) -> bool:
        """
        MongoDBÏóê Ï†ÄÏû•Îêú Ï≤≠ÌÇπ(chunk) Îç∞Ïù¥ÌÑ∞Î•º ElasticsearchÏóê ÏÉâÏù∏ÌïòÎäî Ìï®Ïàò.

        Ï£ºÏñ¥ÏßÑ `file_name` ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú MongoDBÏùò chunk_collection ÏóêÏÑú Î¨∏ÏÑú Ï°∞Í∞ÅÎì§ÏùÑ
        Ï°∞ÌöåÌïú Îí§, ElasticsearchÏùò `index_name` Ïù∏Îç±Ïä§Î°ú bulk APIÎ•º Ïù¥Ïö©Ìï¥ ÏùºÍ¥Ñ ÏÉâÏù∏ÌïúÎã§.
        Ïù¥ Îïå MongoDBÏùò `_id` Í∞íÏùÑ Í∑∏ÎåÄÎ°ú Elasticsearch Î¨∏ÏÑú `_id` Î°ú ÏÇ¨Ïö©ÌïòÏó¨
        Ï§ëÎ≥µ ÏÉâÏù∏ÏùÑ Î∞©ÏßÄÌïòÍ≥†, ÎèôÏùº Î¨∏ÏÑúÍ∞Ä Ïû¨ÏÉâÏù∏Îê† Í≤ΩÏö∞ ÎçÆÏñ¥Ïì∞Í∏∞(upsert)ÎêòÎèÑÎ°ù ÌïúÎã§.

        Args:
            file_name (str): ÏÉâÏù∏Ìï† ÏõêÎ≥∏ Î¨∏ÏÑúÏùò ÌååÏùº Ïù¥Î¶Ñ.
            index_name (str): ÏÉâÏù∏Ïù¥ Ï†ÄÏû•Îê† Elasticsearch Ïù∏Îç±Ïä§ Ïù¥Î¶Ñ. (ÌôîÎ©¥ÏóêÏÑúÎ∂ÄÌÑ∞ ÏÇ¨Ïö©ÏûêÍ∞Ä MSDS/TDS ÏÑ†ÌÉùÌïòÍ∏∞Î°ú ÌñàÏúºÎØÄÎ°ú index_nameÏùÑ ÎÑòÍ≤®Ï§Ñ Ïàò ÏûàÏùÑ Í≤ÉÏúºÎ°ú ÌåêÎã®Ìï®. index_nameÏùÄ ÏÜåÎ¨∏ÏûêÎ°ú msds or tds)

        Returns:
            bool: ÏÉâÏù∏ ÏûëÏóÖÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏôÑÎ£åÎêòÎ©¥ True, 
                Ï≤≠ÌÇπ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÍ±∞ÎÇò ÏÉâÏù∏ Í≥ºÏ†ïÏóêÏÑú Ïò§Î•òÍ∞Ä Î∞úÏÉùÌïòÎ©¥ False.

        Notes:
            - generator Î∞©ÏãùÏúºÎ°ú bulk ÏöîÏ≤≠ÏùÑ Ï≤òÎ¶¨ÌïòÏó¨ ÎåÄÎüâ Îç∞Ïù¥ÌÑ∞ÏóêÎèÑ Î©îÎ™®Î¶¨ ÏïàÏ†ÑÌï®.
            - ÏÉâÏù∏ Í∞úÏàòÏôÄ ÏóêÎü¨ Í∞úÏàòÎäî Ìï®Ïàò ÎÇ¥Î∂ÄÏóêÏÑú Î°úÍ∑∏Î°ú Ï∂úÎ†•Îê®.
        """

        # MongoDBÏóêÏÑú Ï≤≠ÌÅ¨Îì§ Í∞ÄÏ†∏Ïò§Í∏∞
        chunks = self.chunk_collection.find({"file_info.file_name": file_name})

        # Ï≤≠ÌÅ¨ Îç∞Ïù¥ÌÑ∞Î•º Î™®Îëê Î©îÎ™®Î¶¨Ïóê Ïò¨Î¶¨Î©¥ ÎπÑÌö®Ïú®Ï†ÅÏù¥ÎØÄÎ°ú, Ï≤´Î≤àÏß∏ Ï≤≠ÌÅ¨ Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Ï§ÄÏúºÎ°ú Ï≤≠ÌÅ¨ Ï°¥Ïû¨Ïó¨Î∂Ä ÌôïÏù∏
        first_chunk = next(chunks, None)

        if first_chunk is None:
            print(f"‚ö†Ô∏è No chunk data found for file: {file_name}")
            return False

        # Ï≤≠ÌÅ¨Í∞Ä Ï°¥Ïû¨ÌïúÎã§Î©¥ Ïù∏Îç±Ïã± ÏßÑÌñâ
        # actionÏùÄ Í≥µÏãùÎ¨∏ÏÑúÏùò ÌëúÌòÑÏù¥Ïñ¥ÏÑú Îî∞Î¶Ñ
        # Ïù∏Îç±Ïã±Ìï† Îç∞Ïù¥ÌÑ∞Î•º Î™®Îëê Î©îÎ™®Î¶¨Ïóê Ïò¨Î¶¨ÏßÄ ÏïäÍ≥†, generatorÎ•º ÌÜµÌï¥ Îç∞Ïù¥ÌÑ∞Î•º ÌïòÎÇòÏî© ÌùòÎ†§Î≥¥ÎÇ¥Îäî Í≤ÉÏù¥ Elasticsearch Í≥µÏãùÎ¨∏ÏÑúÏóêÏÑú Í∂åÏû•ÌïòÎäî Î∞©ÏãùÏù¥ÎØÄÎ°ú Îî∞Î¶Ñ
        def generate_actions():
            # Ï≤´ Î¨∏ÏÑúÎ∂ÄÌÑ∞ Ï≤òÎ¶¨
            yield {
                "_op_type": "index",
                "_index": index_name,
                "_id": str(first_chunk["_id"]), # MongoDBÏùò _id Í∞íÏùÑ Í∑∏ÎåÄÎ°ú ElasticsearchÏùò _id Í∞íÏúºÎ°ú ÏÇ¨Ïö©
                "_source": {
                    "type": first_chunk.get("type", ""),
                    "content": first_chunk.get("content", ""),
                    "metadata": first_chunk.get("metadata", ""),
                    "file_info": first_chunk.get("file_info", {})
                }
            }

            # ÎÇòÎ®∏ÏßÄ Î¨∏ÏÑú Ï≤òÎ¶¨
            for chunk in chunks:
                yield {
                    "_op_type": "index",
                    "_index": index_name,
                    "_id": str(chunk["_id"]),
                    "_source": {
                        "type": chunk.get("type", ""),
                        "content": chunk.get("content", ""),
                        "metadata": chunk.get("metadata", ""),
                        "file_info": chunk.get("file_info", {})
                    }
                }

        try:
            (success_count, errors) = helpers.bulk(self.elasticsearch_client, generate_actions())

        except Exception as e:
            print(f"‚ùå Error indexing chunks: {e}")
            return False

        error_count = len(errors) if errors else 0

        print(f"‚úÖ Indexed {success_count} chunks into `{index_name}` with {error_count} errors.")
        
        if errors and error_count > 0:
            print("\n‚ö†Ô∏è Detailed errors:")
            for i, err in enumerate(errors, start=1):
                print(f"  {i}. {err}\n")
        else:
            print("üéâ No errors during indexing!")

        return True


    def build_query(query: str, chunk_type: str) -> dict:

        if(chunk_type == "text" or chunk_type == "table"):
            search_field = "content"
        elif(chunk_type == "image"):
            search_field = "metadata"

        return {
            "bool": {
                "must": [
                    {"match": {search_field: query}}
                ],
                "filter": [
                    {"term": {"type": chunk_type}}
                ]
            }
        }


    def search(self, query: str, index_name: list[str], size: int = 10) -> List[Dict[str, Any]]:
        """
        ElasticsearchÏóêÏÑú queryÎ°ú Í≤ÄÏÉâ
        """
        elasticsearch_query = {
            "bool": {
                "should": [
                    {
                        "bool": {
                            "must": [
                                {"match": {"content": query}}
                            ],
                            "filter": [
                                {"terms": {"type": ["text", "table"]}}
                            ]
                        }
                    },
                    {
                        "bool": {
                            "must": [
                                {"match": {"metadata": query}}
                            ],
                            "filter": [
                                {"term": {"type": "image"}}
                            ]
                        }
                    }
                ],
                "minimum_should_match": 1
            }
        }

        response  = self.elasticsearch_client.search(
            index=index_name,
            size=size,
            query=elasticsearch_query
        )

        hits = response["hits"]["hits"]

        scored_results = sorted(
            [
                {
                    "score": hit["_score"],
                    "type": hit["_source"].get("type"),
                    "content": hit["_source"].get("content"),
                    "metadata": hit["_source"].get("metadata"),
                    "file_info": hit["_source"].get("file_info")
                }
                for hit in hits
            ],
            key=lambda result: result["score"],
            reverse=True
        )

        results = [
            {
                "type": scored_result["type"],
                "content": scored_result["content"],
                "metadata": scored_result["metadata"],
                "file_info": scored_result["file_info"]
            }
            for scored_result in scored_results
        ]

        print(f"‚úÖ Found {len(results)} results")
        return results