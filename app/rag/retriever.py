from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from typing import List
from pathlib import Path
import requests
from dotenv import load_dotenv
import os
import numpy as np

def init():
    """
    ëª¨ë¸ê³¼ client ì—°ê²° ì´ˆê¸°í™”
    """
    # Qwen ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    model = SentenceTransformer('Qwen/Qwen3-Embedding-0.6B', trust_remote_code=True)

    # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = QdrantClient(url="http://localhost:6333")

    return model, client

def query_embedding(model: SentenceTransformer, text: str) -> List[float]:
    """
    ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜

    Args:
        model: SentenceTransformer ëª¨ë¸
        text: ì¿¼ë¦¬ í…ìŠ¤íŠ¸
    Returns:
        ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
    """
    embedding = model.encode([text], normalize_embeddings=True)
    return embedding[0]


def search_similar_chunks(client: QdrantClient, qv, collections: list[str], top_k=5):
    """
    ì¿¼ë¦¬ ë²¡í„°ì™€ ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰

    Args:
        client: QdrantClient ì¸ìŠ¤í„´ìŠ¤
        qv: ì¿¼ë¦¬ ë²¡í„°
        collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        top_k: ìƒìœ„ kê°œ ê²°ê³¼ ë°˜í™˜
    Returns:
        ìœ ì‚¬í•œ ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """

    raw_results = []
    for collection in collections: # ê° ì»¬ë ‰ì…˜ì— ëŒ€í•´ ê²€ìƒ‰
        raw_result = client.query_points(
            collection_name=collection,
            query=qv.tolist() if hasattr(qv, 'tolist') else qv,
            limit=top_k
        )
        raw_results.extend(raw_result.points)

    # ì „ì²´ ê²°ê³¼ score ê¸°ì¤€ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
    raw_results.sort(key=lambda x: x.score, reverse=True)

    search_result = []
    search_result = [
        {
            "score": r.score,
            "chunk": r.payload
        }
        for r in raw_results
    ]

    return search_result

if __name__ == "__main__":
    model, client = init()
    example_query = "Product Number 1509ì˜ ì‹¤í—˜ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì‹œì˜¤"

    qv = query_embedding(model, example_query)
    results = search_similar_chunks(client, qv, ["msds", "tds"], top_k=2)

    prompt = f"""
    ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê³  í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
    
    ì§ˆë¬¸: {example_query}
    Qdrant ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {results}
    """

    BASE_DIR = Path(__file__).resolve().parents[1]  # root ê²½ë¡œ
    load_dotenv(BASE_DIR / "common" / ".env")

    RUNPOD_URI = os.getenv("RUNPOD_URI")
    RUNPOD_LLM_MODEL = os.getenv("RUNPOD_LLM_MODEL")
    TIMEOUT = os.getenv("TIMEOUT")

    # ë‹µë³€ ìš”ì²­
    url = f"{RUNPOD_URI}/api/generate"
    payload = {"model": RUNPOD_LLM_MODEL, "prompt": prompt, "stream": False}
    timeout = float(TIMEOUT) if TIMEOUT else None
    response = requests.post(url, json=payload, timeout=timeout)

    try:
        response.raise_for_status() # ì—ëŸ¬ë‚˜ë©´ ì˜ˆì™¸ ë°œìƒì‹œí‚´
    except requests.RequestException as e:
        print(f"HTTP request failed: {e}")

    print(f"ğŸ” LLM response: {response.json()['response']}")