from elasticsearch import Elasticsearch
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer
from qdrant_client.models import VectorParams, Distance
from neo4j import GraphDatabase

import os
from dotenv import load_dotenv
import json
import requests
import asyncio

from app.rag.elasticsearch_indexer import ElasticsearchIndexer
from app.rag.retriever import query_embedding, search_similar_chunks
from app.rag.neo4j_knowledge_graph import Neo4jKnowledgeGraph


class Search:
    load_dotenv()

    def __init__(self):

        # --- Indexing Database Client ---
        ELASTIC_PASSWORD = os.getenv("ELASTIC_PASSWORD")

        self.indexing_db_client = Elasticsearch(
            "http://localhost:9200",
            basic_auth=("elastic", ELASTIC_PASSWORD)
        )

        # --- Embedding Model Client ---
        self.embedding_model = SentenceTransformer('Qwen/Qwen3-Embedding-0.6B', trust_remote_code=True)

        # --- Vector Database Client ---
        self.vector_db_client = QdrantClient(url="http://localhost:6333")

        # collections = ["msds", "tds"]
        # for collection in collections:
        #     self.vector_db_client.recreate_collection(
        #         collection_name=collection,
        #         vectors_config=VectorParams(
        #             size=1024,
        #             distance=Distance.COSINE
        #         )
        #     )
        #     print(f"ì»¬ë ‰ì…˜ '{collection}' ìƒì„± ì™„ë£Œ.")

        # --- Knowledge Graph Client ---
        NEO4J_URI = os.getenv("NEO4J_URI")
        NEO4J_AUTH = ("neo4j", os.getenv("NEO4J_PASSWORD"))

        self.neo4j_driver = GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH)


    def _keyword_search(self, query: str, collections: list[str]):
        """
        í‚¤ì›Œë“œ ê²€ìƒ‰ ìˆ˜í–‰
        """
        elasticsearch_indexer = ElasticsearchIndexer()
        elasticsearch_indexer.ensure_index(collections)
        return elasticsearch_indexer.keyword_search(query, collections)

    def _vector_search(self, query: str, collections: list[str]):
        """
        ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
        """
        qv = query_embedding(self.embedding_model, query)
        print("ì¿¼ë¦¬ ì„ë² ë”© ì™„ë£Œ")
        results = search_similar_chunks(self.vector_db_client, qv, collections, 5)
        print("ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ")
        return results

    async def _async_graph_search(self, query: str):
        """
        ê·¸ë˜í”„ ê²€ìƒ‰ ìˆ˜í–‰
        """
        neo4j_knowledge_graph = Neo4jKnowledgeGraph()
        return await neo4j_knowledge_graph.async_search_graph(query)

    async def async_generate_rag_answer(self, query: str, collections: list[str]):
        """
        ë‹µë³€ ìƒì„± ìˆ˜í–‰
        """
        keyword_results = json.dumps(self._keyword_search(query, collections), ensure_ascii=False, indent=2)
        vector_results = json.dumps(self._vector_search(query, collections), ensure_ascii=False, indent=2)
        graph_results = json.dumps(await self._async_graph_search(query), ensure_ascii=False, indent=2)

        prompt = f"""
        ë‹¹ì‹ ì€ ì‚¼ì„±ì „ì ìƒì‚°ê¸°ìˆ ì—°êµ¬ì†Œì˜ ì†Œì¬ ë¬¼ì„± ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ê·¼ê±° ì¤‘ì‹¬ì˜ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ë‹¹ì‹ ì˜ ëª¨ë“  ë‹µë³€ì€ ì•„ë˜ ì œê³µëœ ë¬¸ì„œ(JSON í˜•íƒœ)ì˜ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤. 
        ì¶”ë¡ ì„ í•  ë•Œë„ ë°˜ë“œì‹œ ë¬¸ì„œì˜ ë‚´ìš©ì„ ê·¼ê±°ë¡œ í•´ì•¼ í•˜ë©°, ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ê³  ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”.

        -----------------------------
        [ì‚¬ìš©ì ì§ˆë¬¸]
        {query}
        -----------------------------

        [ê²€ìƒ‰ëœ ë¬¸ì„œ(JSON)]
        ì•„ë˜ JSON ë°°ì—´ì˜ ê° ìš”ì†ŒëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œ ì¡°ê°(chunk)ì…ë‹ˆë‹¤.
        ê° chunkëŠ” ë‹¤ìŒ ê°’ì„ í¬í•¨í•©ë‹ˆë‹¤:
        - type: text/table/image/link ë“± ë¬¸ì„œ ìœ í˜•
        - content: imgaeì˜ ê²½ë¡œ | linkì˜ ì›ë³¸ë§í¬ | List[dict[str, str]] í˜•íƒœë¡œ ì–¸í”¼ë´‡ëœ html tableì˜ ë‚´ìš© | textì˜ ë‚´ìš©
        - metadata: imageì˜ ë©”íƒ€ë°ì´í„° | linkì˜ ë©”íƒ€ë°ì´í„° | None
        - file_info: {{
            "file_uuid" : "ë°±ì—”ë“œì—ì„œ ë„˜ì–´ì˜¤ëŠ” Doc ID",
            "file_name" : "íŒŒì¼ ì´ë¦„",
            "collections" : ["collection ì´ë¦„1", "collection ì´ë¦„2", ...],
            "page_num" : í˜ì´ì§€ ë²ˆí˜¸ ì •ìˆ˜ ë°°ì—´
        }}

        ê²€ìƒ‰ëœ ë¬¸ì„œ(JSON):
        [í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼]
        {keyword_results}

        [ë²¡í„° ê²€ìƒ‰ ê²°ê³¼]
        {vector_results}

        [ê·¸ë˜í”„ ê²€ìƒ‰ ê²°ê³¼]
        {graph_results}

        -----------------------------
        [ì§€ì¹¨]

        1. ë°˜ë“œì‹œ ë¬¸ì„œ(JSON) ì† text ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
        2. ë‹µë³€ì—ëŠ” ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
        (A) ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•œ ë‹µë³€
        (B) ë‹µë³€ì— ì‚¬ìš©ëœ ê·¼ê±°ì˜ ì¶œì²˜ (file_uuid(íŒŒì¼ ê³ ìœ  UUID), file_name(íŒŒì¼ëª…), page_num(í˜ì´ì§€ ë²ˆí˜¸))
        3. ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ì°¸ì¡°í–ˆë‹¤ë©´ ì¶œì²˜ë¥¼ ëª¨ë‘ í‘œê¸°í•˜ì„¸ìš”.
        4. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” "ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”. ì´ë•Œì—ëŠ” file_infoì— ëŒ€í•œ ë‚´ìš©ì„ ë¹„ì›Œë‘ì„¸ìš”.
        5. JSON ì•ˆì˜ êµ¬ì¡°(key ì´ë¦„)ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
        6. image / link íƒ€ì… chunkëŠ” metadataë¥¼ ìš”ì•½í•´ í…ìŠ¤íŠ¸ì²˜ëŸ¼ ë‹¤ë¤„ë„ ë©ë‹ˆë‹¤.

        -----------------------------
        [ì¶œë ¥ í˜•ì‹]
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:

        {{
            "answer" : "ë‹µë³€",
            "file_info" : {{
                "file_uuid" : "ë°±ì—”ë“œì—ì„œ ë„˜ì–´ì˜¤ëŠ” Doc ID",
                "file_name" : "íŒŒì¼ ì´ë¦„",
                "page_num" : í˜ì´ì§€ ë²ˆí˜¸ ì •ìˆ˜ ë°°ì—´
            }}
        }}
        """

        RUNPOD_URI = os.getenv("RUNPOD_URI")
        RUNPOD_LLM_MODEL = os.getenv("RUNPOD_LLM_MODEL")
        TIMEOUT = os.getenv("TIMEOUT")

        # ë‹µë³€ ìš”ì²­
        url = f"{RUNPOD_URI}/api/generate"
        payload = {"model": RUNPOD_LLM_MODEL, "prompt": prompt, "stream": False}
        timeout = float(TIMEOUT) if TIMEOUT else None
        response = requests.post(url, json=payload, timeout=timeout)

        print(prompt)

        try:
            response.raise_for_status()
        except requests.RequestException as e:
            print(f"âŒ HTTP request failed: {e}")

        print(f"ğŸ” LLM response: {response.json()['response']}")

        return response.json()['response']


if __name__ == "__main__":
    search = Search()

    questions = [
        "í†¨ë£¨ì—”ì˜ ë“ëŠ”ì  ë²”ìœ„ëŠ”?",
        "ì•„ì„¸í‹¸ë Œì˜ CAS ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€?",
        "ìˆ˜ì†Œì¶©ì „ì†Œìš© ìˆ˜ì†Œì˜ ê¶Œê³ ìš©ë„ëŠ”?"
    ]

    for question in questions:
        print(f"\n{'='*80}")
        print(f"ì§ˆë¬¸: {question}")
        print(f"{'='*80}\n")
        asyncio.run(search.async_generate_rag_answer(question, ["msds"]))